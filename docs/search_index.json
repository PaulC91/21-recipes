[
["index.html", "21 Recipes for Mining Twitter Data with rtweet Preface", " 21 Recipes for Mining Twitter Data with rtweet Bob Rudis 2018-01-05 Preface I’m using this as way to familiarize myself with bookdown so I don’t make as many mistakes with my web scraping field guide book. It’s based on Matthew R. Russell’s book. That book is out of distribution and much of the content is in Matthew’s “Mining the Social Web” book. There will be many similarities between his “21 Recipes” book and this book on purpose. I am not claiming originality in this work, just making an R-centric version of the cookbook. As he states in his tome, “this intentionally terse recipe collection provides you with 21 easily adaptable Twitter mining recipes”. The recipes contained in this book use the rtweet package by Michael W. Kearney. I’ll be using the GitHub version of the package since it has some cutting-edge features and bug-fixes in it. You can install the GitHub version of [rtweet] by first installing the devtools package via: install.packages(&quot;devtools&quot;) then installing the GitHub rtweet package via: devtools::install_github(&quot;mkearney/rtweet&quot;) NOTE: If you try to run examples in this book and receive an error about a package not being found or not available, you’ll need to triage it by using one of the above methods. If any GitHub packages are used, each initial library() call will have a comment after it noting which repository/packagename to use the devtools method with. Matthew also states that “one other thing you should consider doing up front, if you haven’t already, is quickly skimming through the official Twitter API documentation and related development documents linked on that page. Twitter has a very easy-to-use API with a lot of degrees of freedom”. Michael has documented rtweet well, but reading the official documentation will really help. This book also makes extensive use of the tidyverse meta-package. You will need to: install.packages(&quot;tidyverse&quot;) if you have not used packages from it before (it may take a few minutes, especially on Linux systems). "],
["about-the-author.html", "About the Author", " About the Author Bob Rudis is a cybersecurity researcher and R afficionado presently thwartng cyber evildoers as [Master] Chief Data Scientist at Rapid7. He was formerly a Security Data Scientist &amp; Managing Principal at Verizon, overseeing the team that produces the annual Data Breach Investigations Report. Bob is a serial tweeter (https://twitter.com/hrbrmstr), avid blogger (https://rud.is/b), author (Data-Driven Security — [http://amzn.to/2CKvrqX]), Stack Overflow contributor (https://stackoverflow.com/users/1457051/hrbrmstr), speaker, and regular contributor to the open source community (https://github.com/hrbrmstr). He is the author of several packages on CRAN including ggalt, hrbrthemes, waffle, statebins. "],
["using-oauth-to-access-twitter-apis.html", "Recipe 1 Using OAuth to Access Twitter APIs 1.1 Problem 1.2 Solution 1.3 Discussion 1.4 See Also", " Recipe 1 Using OAuth to Access Twitter APIs 1.1 Problem You want to access your own data or another user’s data for analysis. 1.2 Solution Take advantage of Twitter’s OAuth implementation to gain full access to Twitter’s entire API. 1.3 Discussion Twitter uses OAuth Core 1.0 Revision A (“OAuth 1.0a” for short &amp; to further reduce verbosity, “oauth” from now on). A few, key purposes of oauth in the context of Twitter are: to ensure end-users know an application is registered with Twitter, and know who the author(s) fo the application are; enable limiting what operations an application can perform with your Twitter account; obviate the need to share your actual Twitter username and password with a third party, which also enables recovation of application access to your Twitter account without resetting your password. The rtweet package takes this one step further by having you create an “application”, which is nothing more than you setting up some basic configuration information. To do so, you must visit apps.twitter.com and create a new application. You will need to provide values for the following fields: Name : something you’ll remember Description : another place you can remind yourself what this is for Website : something that points to information you can use to associate this app when you’ve forgotten about it 5 years from now Callback URL : This must be http://127.0.0.1:1410 (we’ll see why in a moment) tick the agreement checkbox Once you submit that form, you’ll see a new page: Select the “Keys and Access Tokens” tab to see important information you’ll need: From the previous page and this page, you’ll need the: Application Name (which is my_rtweet_application in this example but you need to use the one you supplied) Consumer Key (API Key) (which is akNTqsfSjJFQse1c55Vrm6BcZ in this example but you need to use your own) Consumer Secret (API Secret) (which is HFF77rxG5HTx4Ui7RbxYVjoyUup5h0ncls92Q88ddE0n4YFJZN in this example, but — again — you need to use your own) Store both of those in your ~/.Renviron file. If you’re unfamiliar with how to do that, see this handy section from “Efficient R Programming”. I prefer storing these as such: TWITTER_APP=my_rtweet_application TWITTER_CONSUMER_KEY=akNTqsfSjJFQse1c55Vrm6BcZ TWITTER_CONSUMER_SECRET=HFF77rxG5HTx4Ui7RbxYVjoyUup5h0ncls92Q88ddE0n4YFJZN By storing these values in ~/.Renviron you avoid exposing them in subdirectories or within scripts and will always be able to reference them. Now you can enable your Twitter account with this application and create a token: create_token( app = Sys.getenv(&quot;TWITTER_APP&quot;), consumer_key = Sys.getenv(&quot;TWITTER_CONSUMER_KEY&quot;), consumer_secret = Sys.getenv(&quot;TWITTER_CONSUMER_SECRET&quot;) ) -&gt; twitter_token You should see a browser window appear that has an authorization form in it: You’ll also see: Waiting for authentication in browser... Press Esc/Ctrl + C to abort in the R console. The rtweet package used httr to send an oauth request to Twitter and then started up a local web server (this is why that weird localhost URL from before is necessary). When you authorize the application, the browser sends a response back to the web server httr spun up with some important, secret information that will make it possible for you to never have to do this oauth dance again. If everything was successful, you’ll see: Authentication complete. Please close this page and return to R. in the browser window, and: Authentication complete. in the R console. The next step is very important. Save the secret token you just received this way: saveRDS(twitter_token, &quot;~/.rtweet.rds&quot;) then create one more environment variable in ~/.Renviron: TWITTER_PAT=~/.rtweet.rds That last step will help ensure you never have to deal with oauth again (until you want to). Keep this token file safe!! It enables anyone who has it to do virtually anything with your account. If you believe it has been exposed, go back to apps.twitter.com and delete the application (you can also choose to regenerate the Consumer Key and Consumer Secret, but it’s often easier to just make a new application). You should also review your Twitter apps and ensure it’s removed from there as well. Use the Revoke access button if it is: 1.4 See Also The official rtweet authentication vignette "],
["looking-up-the-trending-topics.html", "Recipe 2 Looking Up the Trending Topics 2.1 Problem 2.2 Solution 2.3 Discussion 2.4 See Also", " Recipe 2 Looking Up the Trending Topics 2.1 Problem You want to keep track of the trending topics on Twitter over a period of time. 2.2 Solution Use rtweet::trends_available() to see trend areas and rtweet::get_trends() to pull trends, after which you can setup a task to retrieve and cache the trend data periodically. 2.3 Discussion Twitter has extensive information on trending topics and their API enables you to see topics that are trending globally or regionally. Twitter uses Yahoo! Where on Earth identifiers (WOEIDs) for the regions which can be obtained from rtweet::trends_available(): library(rtweet) library(tidyverse) (trends_avail &lt;- trends_available()) ## # A tibble: 467 x 8 ## name url parentid ## * &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Worldwide http://where.yahooapis.com/v1/place/1 0 ## 2 Winnipeg http://where.yahooapis.com/v1/place/2972 23424775 ## 3 Ottawa http://where.yahooapis.com/v1/place/3369 23424775 ## 4 Quebec http://where.yahooapis.com/v1/place/3444 23424775 ## 5 Montreal http://where.yahooapis.com/v1/place/3534 23424775 ## 6 Toronto http://where.yahooapis.com/v1/place/4118 23424775 ## 7 Edmonton http://where.yahooapis.com/v1/place/8676 23424775 ## 8 Calgary http://where.yahooapis.com/v1/place/8775 23424775 ## 9 Vancouver http://where.yahooapis.com/v1/place/9807 23424775 ## 10 Birmingham http://where.yahooapis.com/v1/place/12723 23424975 ## # ... with 457 more rows, and 5 more variables: country &lt;chr&gt;, ## # woeid &lt;int&gt;, countryCode &lt;chr&gt;, code &lt;int&gt;, place_type &lt;chr&gt; glimpse(trends_avail) ## Observations: 467 ## Variables: 8 ## $ name &lt;chr&gt; &quot;Worldwide&quot;, &quot;Winnipeg&quot;, &quot;Ottawa&quot;, &quot;Quebec&quot;, &quot;Mont... ## $ url &lt;chr&gt; &quot;http://where.yahooapis.com/v1/place/1&quot;, &quot;http://w... ## $ parentid &lt;int&gt; 0, 23424775, 23424775, 23424775, 23424775, 2342477... ## $ country &lt;chr&gt; &quot;&quot;, &quot;Canada&quot;, &quot;Canada&quot;, &quot;Canada&quot;, &quot;Canada&quot;, &quot;Canad... ## $ woeid &lt;int&gt; 1, 2972, 3369, 3444, 3534, 4118, 8676, 8775, 9807,... ## $ countryCode &lt;chr&gt; NA, &quot;CA&quot;, &quot;CA&quot;, &quot;CA&quot;, &quot;CA&quot;, &quot;CA&quot;, &quot;CA&quot;, &quot;CA&quot;, &quot;CA&quot;... ## $ code &lt;int&gt; 19, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7... ## $ place_type &lt;chr&gt; &quot;Supername&quot;, &quot;Town&quot;, &quot;Town&quot;, &quot;Town&quot;, &quot;Town&quot;, &quot;Town... The Twitter API is somewhat unforgiving and unfriendly when you use it directly since it requires the use of a WOEID. Michael has made life much easier for us all by enabling the use of names or regular expressions when asking for trends from a particular place. That means we don’t even need to care about capitalization: (us &lt;- get_trends(&quot;united states&quot;)) ## # A tibble: 50 x 9 ## trend ## * &lt;chr&gt; ## 1 #backtowork ## 2 #TuesdayThoughts ## 3 #SavannahHodaTODAY ## 4 Justin Timberlake ## 5 #MyTVShowWasCanceledBecause ## 6 #AM2DM ## 7 Carrie Underwood ## 8 The Trump Effect ## 9 Sean Ryan ## 10 Micah Parsons ## # ... with 40 more rows, and 8 more variables: url &lt;chr&gt;, ## # promoted_content &lt;lgl&gt;, query &lt;chr&gt;, tweet_volume &lt;int&gt;, place &lt;chr&gt;, ## # woeid &lt;int&gt;, as_of &lt;dttm&gt;, created_at &lt;dttm&gt; glimpse(us) ## Observations: 50 ## Variables: 9 ## $ trend &lt;chr&gt; &quot;#backtowork&quot;, &quot;#TuesdayThoughts&quot;, &quot;#Savannah... ## $ url &lt;chr&gt; &quot;http://twitter.com/search?q=%23backtowork&quot;, ... ## $ promoted_content &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... ## $ query &lt;chr&gt; &quot;%23backtowork&quot;, &quot;%23TuesdayThoughts&quot;, &quot;%23Sa... ## $ tweet_volume &lt;int&gt; 27544, 30822, 10279, NA, NA, NA, NA, 12000, N... ## $ place &lt;chr&gt; &quot;United States&quot;, &quot;United States&quot;, &quot;United Sta... ## $ woeid &lt;int&gt; 23424977, 23424977, 23424977, 23424977, 23424... ## $ as_of &lt;dttm&gt; 2018-01-02 16:34:11, 2018-01-02 16:34:11, 20... ## $ created_at &lt;dttm&gt; 2018-01-02 16:27:46, 2018-01-02 16:27:46, 20... Twitter’s documentation states that trends are updated every 5 minutes, which means you should not call the API more frequently than that and their current API rate-limit (Twitter puts some restrictions on how frequently you can call certain API targets) is 75 requests per 15-minute window. The rtweet::get_trends() function returns a data frame. Our ultimate goal is to retrieve the trends data on a schedule and cache it. There are numerous — and usually complex – ways to schedule jobs. One cross-platform solution is to use R itself to run a task periodically. This means keeping an R console open and running at all times, so is far from an optimal solution. See the taskscheduleR package for other ideas on how to setup more robust scheduled jobs. In this example, we will: use a SQLite database to store the trends use the DBI add RSQlite packages to work with this database setup a never-ending loop with Sys.sleep() providing a pause between requests library(DBI) library(RSQLite) library(rtweet) # mkearney/rtweet repeat { message(&quot;Retrieveing trends...&quot;) # optional us &lt;- get_trends(&quot;united states&quot;) db_con &lt;- dbConnect(RSQLite::SQLite(), &quot;data/us-trends.db&quot;) dbWriteTable(db_con, &quot;us_trends&quot;, us, append=TRUE) # append=TRUE will update the table vs overwrite and also create it on first run if it does not exist dbDisconnect(db_con) Sys.sleep(10 * 60) # sleep for 10 minutes } Later on, we can look at this data with dplyr/dbplyr: library(dplyr) trends_db &lt;- src_sqlite(&quot;data/us-trends.db&quot;) us &lt;- tbl(trends_db, &quot;us_trends&quot;) select(us, trend) ## # Source: lazy query [?? x 1] ## # Database: sqlite 3.19.3 ## # [/Users/hrbrmstr/Development/21-recipes/data/us-trends.db] ## trend ## &lt;chr&gt; ## 1 #TuesdayThoughts ## 2 #backtowork ## 3 #SavannahHodaTODAY ## 4 Justin Timberlake ## 5 #MyTVShowWasCanceledBecause ## 6 #AM2DM ## 7 The Trump Effect ## 8 Carrie Underwood ## 9 Sean Ryan ## 10 Larry Krasner ## # ... with more rows 2.4 See Also RSQlite quick reference Introduction to dbplyr : http://dbplyr.tidyverse.org/articles/dbplyr.html "],
["extracting-tweet-entities.html", "Recipe 3 Extracting Tweet Entities 3.1 Problem 3.2 Solution 3.3 Discussion 3.4 See Also", " Recipe 3 Extracting Tweet Entities 3.1 Problem You want to extract tweet entities such as @mentions, #hashtags, and short URLs from Twitter search results or other batches of tweets. 3.2 Solution Use rtweet::search_tweets() or any of the timeline functions in rtweet. 3.3 Discussion Michael has provided a very powerful search interace for Twitter data mining. rtweet::search_tweets() retrieves, parses and extracts an asounding amount of data for you to then use. Let’s search Twitter for the #rstats hashtag and see what is available: library(rtweet) library(tidyverse) (rstats &lt;- search_tweets(&quot;#rstats&quot;, n=300)) # pull 300 tweets that used the &quot;#rstats&quot; hashtag ## # A tibble: 300 x 42 ## status_id created_at user_id ## &lt;chr&gt; &lt;dttm&gt; &lt;chr&gt; ## 1 948239409790337024 2018-01-02 17:07:47 62219905 ## 2 948238781018136577 2018-01-02 17:05:17 844152803991994368 ## 3 948238133396758529 2018-01-02 17:02:43 1885980073 ## 4 948237585435983873 2018-01-02 17:00:32 2311645130 ## 5 948237466556825600 2018-01-02 17:00:04 933993004133732352 ## 6 948237231604621312 2018-01-02 16:59:08 2359597790 ## 7 948236927194542080 2018-01-02 16:57:55 944231 ## 8 948236596352114689 2018-01-02 16:56:36 734457714567438337 ## 9 948235971501481985 2018-01-02 16:54:07 847851963773460481 ## 10 948235268297052161 2018-01-02 16:51:19 1308811981 ## # ... with 290 more rows, and 39 more variables: screen_name &lt;chr&gt;, ## # text &lt;chr&gt;, source &lt;chr&gt;, reply_to_status_id &lt;chr&gt;, ## # reply_to_user_id &lt;chr&gt;, reply_to_screen_name &lt;chr&gt;, is_quote &lt;lgl&gt;, ## # is_retweet &lt;lgl&gt;, favorite_count &lt;int&gt;, retweet_count &lt;int&gt;, ## # hashtags &lt;list&gt;, symbols &lt;list&gt;, urls_url &lt;list&gt;, urls_t.co &lt;list&gt;, ## # urls_expanded_url &lt;list&gt;, media_url &lt;list&gt;, media_t.co &lt;list&gt;, ## # media_expanded_url &lt;list&gt;, media_type &lt;list&gt;, ext_media_url &lt;list&gt;, ## # ext_media_t.co &lt;list&gt;, ext_media_expanded_url &lt;list&gt;, ## # ext_media_type &lt;lgl&gt;, mentions_user_id &lt;list&gt;, ## # mentions_screen_name &lt;list&gt;, lang &lt;chr&gt;, quoted_status_id &lt;chr&gt;, ## # quoted_text &lt;chr&gt;, retweet_status_id &lt;chr&gt;, retweet_text &lt;chr&gt;, ## # place_url &lt;chr&gt;, place_name &lt;chr&gt;, place_full_name &lt;chr&gt;, ## # place_type &lt;chr&gt;, country &lt;chr&gt;, country_code &lt;chr&gt;, ## # geo_coords &lt;list&gt;, coords_coords &lt;list&gt;, bbox_coords &lt;list&gt; glimpse(rstats) ## Observations: 300 ## Variables: 42 ## $ status_id &lt;chr&gt; &quot;948239409790337024&quot;, &quot;9482387810181365... ## $ created_at &lt;dttm&gt; 2018-01-02 17:07:47, 2018-01-02 17:05:... ## $ user_id &lt;chr&gt; &quot;62219905&quot;, &quot;844152803991994368&quot;, &quot;1885... ## $ screen_name &lt;chr&gt; &quot;alisonmarigold&quot;, &quot;rweekly_live&quot;, &quot;C_Ba... ## $ text &lt;chr&gt; &quot;RT @sellorm: Introducing the Field Gui... ## $ source &lt;chr&gt; &quot;Carbon v.2&quot;, &quot;R Weekly Live&quot;, &quot;Twitter... ## $ reply_to_status_id &lt;chr&gt; NA, NA, NA, NA, NA, NA, &quot;94823184946102... ## $ reply_to_user_id &lt;chr&gt; NA, NA, NA, NA, NA, NA, &quot;18931434&quot;, NA,... ## $ reply_to_screen_name &lt;chr&gt; NA, NA, NA, NA, NA, NA, &quot;RussellSPierce... ## $ is_quote &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALS... ## $ is_retweet &lt;lgl&gt; TRUE, FALSE, TRUE, FALSE, FALSE, FALSE,... ## $ favorite_count &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ... ## $ retweet_count &lt;int&gt; 100, 0, 13, 0, 0, 0, 0, 1, 15, 100, 0, ... ## $ hashtags &lt;list&gt; [&quot;rstats&quot;, &lt;&quot;rstats&quot;, &quot;datascience&quot;&gt;, ... ## $ symbols &lt;list&gt; [NA, NA, NA, NA, NA, NA, NA, NA, NA, N... ## $ urls_url &lt;list&gt; [&quot;blog.sellorm.com/2018/01/01/fie\\u202... ## $ urls_t.co &lt;list&gt; [&quot;https://t.co/Hfrs1fi74u&quot;, &quot;https://t... ## $ urls_expanded_url &lt;list&gt; [&quot;http://blog.sellorm.com/2018/01/01/f... ## $ media_url &lt;list&gt; [NA, NA, &quot;http://pbs.twimg.com/media/D... ## $ media_t.co &lt;list&gt; [NA, NA, &quot;https://t.co/W7OtYESyEG&quot;, &quot;h... ## $ media_expanded_url &lt;list&gt; [NA, NA, &quot;https://twitter.com/dataandm... ## $ media_type &lt;list&gt; [NA, NA, &quot;photo&quot;, &quot;photo&quot;, &quot;photo&quot;, NA... ## $ ext_media_url &lt;list&gt; [NA, NA, &quot;http://pbs.twimg.com/media/D... ## $ ext_media_t.co &lt;list&gt; [NA, NA, &quot;https://t.co/W7OtYESyEG&quot;, &quot;h... ## $ ext_media_expanded_url &lt;list&gt; [NA, NA, &quot;https://twitter.com/dataandm... ## $ ext_media_type &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... ## $ mentions_user_id &lt;list&gt; [&quot;14351134&quot;, &quot;25213966&quot;, &quot;3230388598&quot;,... ## $ mentions_screen_name &lt;list&gt; [&quot;sellorm&quot;, &quot;MicrosoftR&quot;, &quot;dataandme&quot;,... ## $ lang &lt;chr&gt; &quot;en&quot;, &quot;en&quot;, &quot;en&quot;, &quot;en&quot;, &quot;en&quot;, &quot;en&quot;, &quot;en... ## $ quoted_status_id &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... ## $ quoted_text &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... ## $ retweet_status_id &lt;chr&gt; &quot;947909537859809281&quot;, NA, &quot;947954865464... ## $ retweet_text &lt;chr&gt; &quot;Introducing the Field Guide to the #rs... ## $ place_url &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... ## $ place_name &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... ## $ place_full_name &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... ## $ place_type &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... ## $ country &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... ## $ country_code &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... ## $ geo_coords &lt;list&gt; [&lt;NA, NA&gt;, &lt;NA, NA&gt;, &lt;NA, NA&gt;, &lt;NA, NA... ## $ coords_coords &lt;list&gt; [&lt;NA, NA&gt;, &lt;NA, NA&gt;, &lt;NA, NA&gt;, &lt;NA, NA... ## $ bbox_coords &lt;list&gt; [&lt;NA, NA, NA, NA, NA, NA, NA, NA&gt;, &lt;NA... From the output, you can see that all the URLs (short and expanded), status id’s, user id’s and other hashtags are all available and all in a tidy data frame. What are the top 10 (with ties) other hashtags used in conjunction with #rstats (for this search group)? select(rstats, hashtags) %&gt;% unnest() %&gt;% mutate(hashtags = tolower(hashtags)) %&gt;% count(hashtags, sort=TRUE) %&gt;% filter(hashtags != &quot;rstats&quot;) %&gt;% top_n(10) ## # A tibble: 11 x 2 ## hashtags n ## &lt;chr&gt; &lt;int&gt; ## 1 datascience 43 ## 2 python 19 ## 3 dataviz 12 ## 4 newyear 11 ## 5 tidyverse 8 ## 6 r 7 ## 7 ggplot2 6 ## 8 regression 6 ## 9 soccersalaries 6 ## 10 analytics 5 ## 11 bigdata 5 3.4 See Also Official Twitter search API documentation Twitter entites information The tidyverse introduction. "],
["searching-for-tweets.html", "Recipe 4 Searching for Tweets 4.1 Problem 4.2 Solution 4.3 Discussion 4.4 See Also", " Recipe 4 Searching for Tweets 4.1 Problem You want to collect a sample of tweets from the public timeline for a custom query. 4.2 Solution Use rtweet::search_tweets() and custom search operators. 4.3 Discussion The Twitter API has free and paid tiers. The free tier is what many of us use and there are a number of operators that can be added to a search query to refine the results. We saw one of those in Recipe 3 by using the #rstats hashtag in the search query. But there are far more options at our disposal. We can see all the #rstats tweets that aren’t retweets: library(rtweet) library(tidyverse) search_tweets(&quot;#rstats -filter:retweets&quot;) %&gt;% select(text) ## # A tibble: 100 x 1 ## text ## &lt;chr&gt; ## 1 &quot;New R Package for #SEO\\n\\nDiscover RsparkleR : a web crawler powered by @S ## 2 Word Embeddings with Keras https://t.co/QHzvmKNdGS #rstats https://t.co/KwD ## 3 Word Embeddings with Keras https://t.co/cbN12jx74j #rstats ## 4 You can read the first chapter of Practical Data Science with R on #liveBoo ## 5 &quot;Big | Data | Insights! https://t.co/hgMeKIOsjQ\\n#in #rstats #datascience&quot; ## 6 Do you have bad R habits? Here&#39;s how to identify and fix them. @MicrosoftR ## 7 What are the resources to learn creating #Chatbot using R? https://t.co/ip9 ## 8 I have been playing with #ggplot2 and I rather like this plot of bird densi ## 9 Linking RStudio and GitHub. Very useful blog for anyone interested in produ ## 10 &quot;@RussellSPierce @davidjayharris After using it for a long time, it&#39;s reall ## # ... with 90 more rows or, all the recent tweet-replies sent to @kearneymw: search_tweets(&quot;to:kearneymw&quot;) %&gt;% select(text) ## # A tibble: 100 x 1 ## text ## &lt;chr&gt; ## 1 @kearneymw @BreitbartNews First thing&#39;s first: Breitbart is NOT &#39;news&#39;. Na ## 2 @kearneymw @Twitter interesting. This is what I see https://t.co/PVcuXp8u0r ## 3 &quot;@kearneymw @Grantimus9 Dang, he was right again.\\n\\nDebate world is small! ## 4 @kearneymw Amazing. Indeed. @Grantimus9 ## 5 &quot;@kearneymw Really good. Thanks. \\n\\n...Eating more fish&quot; ## 6 @kearneymw Examples sing things well (cohort analysis!) always welcome ## 7 @josephofiowa I&#39;m using it as an example of (a) difficulties in making caus ## 8 @kearneymw https://t.co/JI5AZvdoTq ## 9 &quot;@kearneymw Ohhh, this is neat.\\n\\nLol @ the projections that simply omit t ## 10 @kearneymw I just Lacan&#39;t? ## # ... with 90 more rows and, even all the #rstats tweets that have GitHub links in them (but no #python hashtags): search_tweets(&quot;#rstats url:github -#python&quot;) %&gt;% select(text) ## # A tibble: 100 x 1 ## text ## &lt;chr&gt; ## 1 &quot;RT @dataandme: \\U0001f60e\\U0001f4e6 for changing up your R-\\U0001f4ca text ## 2 Linking RStudio and GitHub. Very useful blog for anyone interested in produ ## 3 &quot;New year, new blog! Find out how to build this animation that brings a tSN ## 4 &quot;Open-source #rstats package mclust provides results that are identical to ## 5 &quot;RT @dataandme: \\U0001f60e\\U0001f4e6 for changing up your R-\\U0001f4ca text ## 6 &quot;RT @dataandme: \\U0001f60e\\U0001f4e6 for changing up your R-\\U0001f4ca text ## 7 &quot;RT @ellessenne: That feeling \\U0001f525 thanks #devtools! Interested in co ## 8 &quot;RT @ma_salmon: @zevross I&#39;ll stop the link dumping I promise, but @astroer ## 9 @zevross I&#39;ll stop the link dumping I promise, but @astroeringrand&#39;s recent ## 10 RT @keyboardpipette: @RyanEs Done: https://t.co/kuLOh3liMj My first #rstats ## # ... with 90 more rows 4.4 See Also Twitter standard search operators "],
["extracting-a-retweets-origins.html", "Recipe 5 Extracting a Retweet’s Origins 5.1 Problem 5.2 Solution 5.3 Discussion 5.4 See Also", " Recipe 5 Extracting a Retweet’s Origins 5.1 Problem You want to extract the originating source from a retweet. 5.2 Solution If the tweet’s retweet_count field is greater than 0, extract name out of the tweet’s user field; also parse the text of the tweet with a regular expression. 5.3 Discussion Twitter is pretty darn good about weaponizingutilizing the data on its platform. There aren’t many cases nowadays when you need to parse RT or via in hand-crafted retweets, but it’s good to have the tools in your aresenal when needed. We can pick out all the retweets from #rstats (warning: it’s a retweet-heavy hashtag) and who they refer to using the retweet_count but also looking for a special regular expression (regex) and extracting data that way. First, the modern, API-centric way: library(rtweet) library(tidyverse) rstats &lt;- search_tweets(&quot;#rstats&quot;, n=500) glimpse(rstats) ## Observations: 500 ## Variables: 42 ## $ status_id &lt;chr&gt; &quot;948262548570177536&quot;, &quot;9482624955583692... ## $ created_at &lt;dttm&gt; 2018-01-02 18:39:44, 2018-01-02 18:39:... ## $ user_id &lt;chr&gt; &quot;22462234&quot;, &quot;22462234&quot;, &quot;3367336625&quot;, &quot;... ## $ screen_name &lt;chr&gt; &quot;bffo&quot;, &quot;bffo&quot;, &quot;HeathrTurnr&quot;, &quot;_RCharl... ## $ text &lt;chr&gt; &quot;RT @sellorm: Introducing the Field Gui... ## $ source &lt;chr&gt; &quot;Twitter for iPhone&quot;, &quot;Twitter for iPho... ## $ reply_to_status_id &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... ## $ reply_to_user_id &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... ## $ reply_to_screen_name &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... ## $ is_quote &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALS... ## $ is_retweet &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, TR... ## $ favorite_count &lt;int&gt; 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, ... ## $ retweet_count &lt;int&gt; 112, 25, 2, 1, 1, 25, 8, 0, 112, 4, 112... ## $ hashtags &lt;list&gt; [&quot;rstats&quot;, &quot;rstats&quot;, &quot;rstats&quot;, &lt;&quot;rstat... ## $ symbols &lt;list&gt; [NA, NA, NA, NA, NA, NA, NA, NA, NA, N... ## $ urls_url &lt;list&gt; [&quot;blog.sellorm.com/2018/01/01/fie\\u202... ## $ urls_t.co &lt;list&gt; [&quot;https://t.co/Hfrs1fi74u&quot;, NA, NA, NA... ## $ urls_expanded_url &lt;list&gt; [&quot;http://blog.sellorm.com/2018/01/01/f... ## $ media_url &lt;list&gt; [NA, NA, NA, NA, &quot;http://pbs.twimg.com... ## $ media_t.co &lt;list&gt; [NA, NA, NA, NA, &quot;https://t.co/HpqJm7L... ## $ media_expanded_url &lt;list&gt; [NA, NA, NA, NA, &quot;https://twitter.com/... ## $ media_type &lt;list&gt; [NA, NA, NA, NA, &quot;photo&quot;, NA, NA, &quot;pho... ## $ ext_media_url &lt;list&gt; [NA, NA, NA, NA, &quot;http://pbs.twimg.com... ## $ ext_media_t.co &lt;list&gt; [NA, NA, NA, NA, &quot;https://t.co/HpqJm7L... ## $ ext_media_expanded_url &lt;list&gt; [NA, NA, NA, NA, &quot;https://twitter.com/... ## $ ext_media_type &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... ## $ mentions_user_id &lt;list&gt; [&quot;14351134&quot;, &quot;2167059661&quot;, &lt;&quot;567537377... ## $ mentions_screen_name &lt;list&gt; [&quot;sellorm&quot;, &quot;JennyBryan&quot;, &lt;&quot;KKulma&quot;, &quot;... ## $ lang &lt;chr&gt; &quot;en&quot;, &quot;en&quot;, &quot;en&quot;, &quot;en&quot;, &quot;en&quot;, &quot;en&quot;, &quot;en... ## $ quoted_status_id &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... ## $ quoted_text &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... ## $ retweet_status_id &lt;chr&gt; &quot;947909537859809281&quot;, &quot;9479691476058849... ## $ retweet_text &lt;chr&gt; &quot;Introducing the Field Guide to the #rs... ## $ place_url &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... ## $ place_name &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... ## $ place_full_name &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... ## $ place_type &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... ## $ country &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... ## $ country_code &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... ## $ geo_coords &lt;list&gt; [&lt;NA, NA&gt;, &lt;NA, NA&gt;, &lt;NA, NA&gt;, &lt;NA, NA... ## $ coords_coords &lt;list&gt; [&lt;NA, NA&gt;, &lt;NA, NA&gt;, &lt;NA, NA&gt;, &lt;NA, NA... ## $ bbox_coords &lt;list&gt; [&lt;NA, NA, NA, NA, NA, NA, NA, NA&gt;, &lt;NA... filter(rstats, retweet_count &gt; 0) %&gt;% select(text, mentions_screen_name, retweet_count) %&gt;% mutate(text = substr(text, 1, 30)) %&gt;% unnest() ## # A tibble: 505 x 3 ## text retweet_count mentions_screen_name ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 RT @sellorm: Introducing the F 112 sellorm ## 2 RT @JennyBryan: This overview 25 JennyBryan ## 3 RT @KKulma: Help us improve an 2 KKulma ## 4 RT @KKulma: Help us improve an 2 RLadiesLondon ## 5 RT @ma_salmon: My first #rstat 1 ma_salmon ## 6 RT @ma_salmon: My first #rstat 1 Thoughtfulnz ## 7 My first #rstats post of the y 1 Thoughtfulnz ## 8 RT @edzerpebesma: New #rspatia 25 edzerpebesma ## 9 RT @dataandme: R-code to find 8 dataandme ## 10 RT @dataandme: R-code to find 8 LVaudor ## # ... with 495 more rows The text column was pared down for display brevity. If you run that code snippet you can examine it to see that it identifies the retweets and the first screen name is usually the main reference, but you get all of the screen names from the original tweet for free. Here’s the brute-force way. A regular expression is used that matches the vast majority of retweet formats. The patten looks for them then extracts the first found screen name: # regex mod from https://stackoverflow.com/questions/655903/python-regular-expression-for-retweets filter(rstats, str_detect(text, &quot;(RT|via)((?:[[:blank:]:]\\\\W*@\\\\w+)+)&quot;)) %&gt;% select(text, mentions_screen_name, retweet_count) %&gt;% mutate(extracted = str_match(text, &quot;(RT|via)((?:[[:blank:]:]\\\\W*@\\\\w+)+)&quot;)[,3]) %&gt;% mutate(text = substr(text, 1, 30)) %&gt;% unnest() ## # A tibble: 445 x 4 ## text retweet_count ## &lt;chr&gt; &lt;int&gt; ## 1 RT @rweekly_org: https://t.co/ 23 ## 2 RT @AnalyticsVidhya: What are 4 ## 3 &quot;RT @dataandme: Still a fave \\U0001f4fd &quot; 1 ## 4 RT @sellorm: Introducing the F 108 ## 5 RT @rstudio: Word Embeddings w 4 ## 6 RT @sellorm: Introducing the F 108 ## 7 RT @AnalyticsVidhya: What are 4 ## 8 RT @StatGarrett: Thank you @co 3 ## 9 RT @StatGarrett: Thank you @co 3 ## 10 RT @StatGarrett: Thank you @co 3 ## # ... with 435 more rows, and 2 more variables: extracted &lt;chr&gt;, ## # mentions_screen_name &lt;chr&gt; You should try the above snippets for other tags as there will be cases when the regex will pick up retweets Twitter has failed to capture. 5.4 See Also Twiter official documentation on what happens to retweets when origin tweets are deleted "],
["creating-a-graph-of-retweet-relationships.html", "Recipe 6 Creating a Graph of Retweet Relationships 6.1 Problem 6.2 Solution 6.3 Discussion 6.4 See Also", " Recipe 6 Creating a Graph of Retweet Relationships 6.1 Problem You want to construct and analyze a graph data structure of retweet relationships for a set of query results. 6.2 Solution Query for the topic, extract the retweet origins, and then use igraph to construct a graph to analyze. 6.3 Discussion Recipes 4 and 5 introduced and expanded on searching Twitter plus looking for retweets. The igraph package can be used to capture and analyze details of relationships across retweets. We’ll focus on just examining the Twitter user pair relationships. Let’s get a larger sample this time — 1,500 tweets in #rstats. We can use the technique from the previous recips and: find the retweets (using the API-provided data) expand out all the mentioned screen names create an igraph graph object look at some summary statistics for the graph library(rtweet) library(igraph) library(hrbrthemes) library(tidyverse) rstats &lt;- search_tweets(&quot;#rstats&quot;, n=1500) filter(rstats, retweet_count &gt; 0) %&gt;% select(screen_name, mentions_screen_name) %&gt;% unnest(mentions_screen_name) %&gt;% filter(!is.na(mentions_screen_name)) %&gt;% graph_from_data_frame() -&gt; rt_g You can reference the igraph print() and summary() functions for more information on the output of summary() but output from the following line shows that the graph is Directed with Named vertices and it has 890 vertices and 1,487 edges. summary(rt_g) ## IGRAPH 11823c1 DN-- 890 1487 -- ## + attr: name (v/c) We’ll produce more visualizations in the next recipe, but the degree of graph vertices is one of the most fundamental properties of a graph and it’s much nicer to see the degree distribution than stare at a wall of numbers: ggplot(data_frame(y=degree_distribution(rt_g), x=1:length(y))) + geom_segment(aes(x, y, xend=x, yend=0), color=&quot;slateblue&quot;) + scale_y_continuous(expand=c(0,0), trans=&quot;sqrt&quot;) + labs(x=&quot;Degree&quot;, y=&quot;Density (sqrt scale)&quot;, title=&quot;#rstats Retweet Degree Distribution&quot;) + theme_ipsum_rc(grid=&quot;Y&quot;, axis=&quot;x&quot;) 6.4 See Also igraph "],
["visualizing-a-graph-of-retweet-relationships.html", "Recipe 7 Visualizing a Graph of Retweet Relationships 7.1 Problem 7.2 Solution 7.3 See Also", " Recipe 7 Visualizing a Graph of Retweet Relationships 7.1 Problem You want to visualize a graph of retweets. 7.2 Solution There are a plethora of ways to visualize graph structures in R. One recent and popular one is ggraph. Given the cookbook-nature of this book, we’ll cover one more visualization about retweet relationships. Let’s explore the entire retweet network and label the screen names with the most retweets over a given search term (and use #rstats again, but gather more tweets this time to truly make a spaghetti chart): library(rtweet) library(igraph) library(hrbrthemes) library(ggraph) library(tidyverse) rstats &lt;- search_tweets(&quot;#rstats&quot;, n=1500) # same as previous recipe filter(rstats, retweet_count &gt; 0) %&gt;% select(screen_name, mentions_screen_name) %&gt;% unnest(mentions_screen_name) %&gt;% filter(!is.na(mentions_screen_name)) %&gt;% graph_from_data_frame() -&gt; rt_g To help de-clutter the vertex labels, we’ll only add labels for nodes that have a degree of 20 or more (rough guess — you should look at the degree distribution for more formal work). We’ll also include the degree for those nodes so we can size them properly: V(rt_g)$node_label &lt;- unname(ifelse(degree(rt_g)[V(rt_g)] &gt; 20, names(V(rt_g)), &quot;&quot;)) V(rt_g)$node_size &lt;- unname(ifelse(degree(rt_g)[V(rt_g)] &gt; 20, degree(rt_g), 0)) Now, we’ll creatre the graph. Using ..index.. for the alpha channel will help show edge weight without too much extra effort. Note the heavy customization of geom_node_label(). Thomas made it way too easy to make beautiful network graphs with ggraph: ggraph(rt_g, layout = &#39;linear&#39;, circular = TRUE) + geom_edge_arc(edge_width=0.125, aes(alpha=..index..)) + geom_node_label(aes(label=node_label, size=node_size), label.size=0, fill=&quot;#ffffff66&quot;, segment.colour=&quot;springgreen&quot;, color=&quot;slateblue&quot;, repel=TRUE, family=font_rc, fontface=&quot;bold&quot;) + coord_fixed() + scale_size_area(trans=&quot;sqrt&quot;) + labs(title=&quot;Retweet Relationships&quot;, subtitle=&quot;Most retweeted screen names labeled. Darkers edges == more retweets. Node size == larger degree&quot;) + theme_graph(base_family=font_rc) + theme(legend.position=&quot;none&quot;) 7.3 See Also Enter twitter network analysis r into Google (seriously!). Lots of folks have worked in this space and blogged or wrote about their efforts. "],
["capturing-tweets-in-real-time-with-the-streaming-api.html", "Recipe 8 Capturing Tweets in Real-time with the Streaming API 8.1 Problem 8.2 Solution 8.3 Discussion 8.4 See Also", " Recipe 8 Capturing Tweets in Real-time with the Streaming API 8.1 Problem You want to capture a stream of public tweets in real-time, optionally filtering by select screen names or keywords in the text of the tweet. 8.2 Solution Use rtweet::stream_tweets(). 8.3 Discussion Michael has — once again — made it way too easy to work with Twitter’s API. The rtweet::stream_tweets() function has tons of handy options to help capture tweets in real time. The primary q parameter is very versatile and has four possible capture modes: The default, q = &quot;&quot;, returns a small random sample of all publicly available Twitter statuses. To filter by keyword, provide a comma separated character string with the desired phrase(s) and keyword(s). Track users by providing a comma separated list of user IDs or screen names. Use four latitude/longitude bounding box points to stream by geo location. This must be provided via a vector of length 4, e.g., c(-125, 26, -65, 49). Let’s capture one minute of tweets in the good ol’ U S of A (this is one of Michael’s examples from the manual page for rtweet::stream_tweets(). library(rtweet) library(tidyverse) stream_tweets( lookup_coords(&quot;usa&quot;), # handy helper function in rtweet verbose = FALSE, timeout = (60 * 1), ) -&gt; usa ## Found 500 records... Found 1000 records... Found 1323 records... Imported 1323 records. Simplifying... A 60 second stream resulted in well over 1,000 records. Where are they tweeting from? count(usa, place_full_name, sort=TRUE) ## # A tibble: 724 x 2 ## place_full_name n ## &lt;chr&gt; &lt;int&gt; ## 1 Los Angeles, CA 31 ## 2 Houston, TX 28 ## 3 Manhattan, NY 24 ## 4 Florida, USA 19 ## 5 Georgia, USA 18 ## 6 California, USA 16 ## 7 Pennsylvania, USA 16 ## 8 Texas, USA 15 ## 9 Charlotte, NC 14 ## 10 Chicago, IL 14 ## # ... with 714 more rows What are they tweeting about? unnest(usa, hashtags) %&gt;% count(hashtags, sort=TRUE) %&gt;% filter(!is.na(hashtags)) ## # A tibble: 289 x 2 ## hashtags n ## &lt;chr&gt; &lt;int&gt; ## 1 job 60 ## 2 CareerArc 46 ## 3 Hiring 43 ## 4 hiring 23 ## 5 Job 12 ## 6 Jobs 12 ## 7 Hospitality 7 ## 8 Transportation 6 ## 9 Healthcare 5 ## 10 Nursing 5 ## # ... with 279 more rows What app are they using? count(usa, source, sort=TRUE) ## # A tibble: 26 x 2 ## source n ## &lt;chr&gt; &lt;int&gt; ## 1 Twitter for iPhone 894 ## 2 Twitter for Android 190 ## 3 TweetMyJOBS 81 ## 4 Instagram 62 ## 5 Twitter Web Client 43 ## 6 &quot;Tweetbot for i\\u039fS&quot; 10 ## 7 Foursquare 6 ## 8 Twitter for iPad 6 ## 9 Cities 4 ## 10 SafeTweet by TweetMyJOBS 4 ## # ... with 16 more rows Michael covers the streaming topic in-depth in a vignette. 8.4 See Also Consuming streaming data "],
["making-robust-twitter-requests.html", "Recipe 9 Making Robust Twitter Requests 9.1 Problem 9.2 Solution 9.3 Discussion 9.4 See Also", " Recipe 9 Making Robust Twitter Requests 9.1 Problem You want to write a long-running script that harvests large amounts of data, such as the friend and follower ids for a very popular Twitterer; however, the Twitter API is inherently unreliable and imposes rate limits that require you to always expect the unexpected. 9.2 Solution Use rtweet. 9.3 Discussion No code examples and not much expository in this chaper (unlike it’s Python counterpart). Michael has taken much of the pain away by having the package abstract the rate-limit issues and API wonkiness away from your code. Having said that, you can work on making these Twitter scripts or other scripts more robust by wrapping potentially troublesome calls in purrr::safely()and testing for the result before continuing with data operations. 9.4 See Also purrr::safely() "],
["harvesting-tweets.html", "Recipe 10 Harvesting Tweets 10.1 Problem 10.2 Solution 10.3 Discussion", " Recipe 10 Harvesting Tweets 10.1 Problem You want to harvest and store tweets from a collection of id values, or harvest entire timelines of tweets. 10.2 Solution Use rtweet’s timeline and status functions. 10.3 Discussion Recipe 2 showed how to do this with SQLite. Unlike other API’s rtweet returns a tidy data frame which makes it easy to put data into such rectangular data stores. Rather than repeat the example, let’s take a quick look at all of the harvesting functions in rtweet: get_collections: Get collections by user or status id. get_favorites: Get tweets data for statuses favorited by one or more target users. get_followers: Get user IDs for accounts following target user. get_friends: Get user IDs of accounts followed by target user(s). get_mentions: Get mentions for the authenticating user. get_retweeters: Get user IDs of users who retweeted a given status. get_retweets: Get the most recent retweets of a specific Twitter status get_timeline: Get one or more user timelines (tweets posted by target user(s)). get_timelines: Get one or more user timelines (tweets posted by target user(s)). lookup_collections: Get collections by user or status id. lookup_coords: Get coordinates of specified location. lookup_friendships: Lookup friendship information between two specified users. lookup_statuses: Get tweets data for given statuses (status IDs). lookup_tweets: Get tweets data for given statuses (status IDs). lookup_users: Get Twitter users data for given users (user IDs or screen names). search_tweets: Get tweets data on statuses identified via search query. search_tweets2: Get tweets data on statuses identified via search query. search_users: Get users data on accounts identified via search query. stream_tweets: Collect a live stream of Twitter data. stream_tweets2: Collect a live stream of Twitter data. One handy method for exporting this rectangular tweet data to a file format virtually any collaborator can use is rtweet::write_as_csv() which saves a flattened CSV (no nested column data). "],
["creating-a-tag-cloud-from-tweet-entities.html", "Recipe 11 Creating a Tag Cloud from Tweet Entities 11.1 Problem 11.2 Solution 11.3 Discussion", " Recipe 11 Creating a Tag Cloud from Tweet Entities 11.1 Problem You want to make a meaningless word cloud. 11.2 Solution Use harvesting techniques shown in previous recipes and pass the cloud-destined entities to an R wordcloud package. 11.3 Discussion Word clouds are virtually devoid of meaning. Neiman Lab went to far as to call them harmful. But, this recipe is in the Python version of the book (figures, eh?) and this was desingned to be a 1:1 mapping of said book, so let’s proceed. The folowing uses some handy text taming and word cloud packages to make a collage from #NationalScienceFictionDay tweets: library(rtweet) library(tidytext) library(magick) library(kumojars) # hrbrmstr/kumojars library(kumo) # hrbrmstr/kumo library(tidyverse) scifi &lt;- search_tweets(&quot;#NationalScienceFictionDay&quot;, n=1500) data_frame(txt=str_replace_all(scifi$text, &quot;#NationalScienceFictionDay&quot;, &quot;&quot;)) %&gt;% unnest_tokens(word, txt) %&gt;% anti_join(stop_words, &quot;word&quot;) %&gt;% anti_join(rtweet::stopwordslangs, &quot;word&quot;) %&gt;% anti_join(data_frame(word=c(&quot;https&quot;, &quot;t.co&quot;)), &quot;word&quot;) %&gt;% # need to make a more technical stopwords list or clean up the text better filter(nchar(word)&gt;3) %&gt;% pull(word) %&gt;% paste0(collapse=&quot; &quot;) -&gt; txt cloud_img &lt;- word_cloud(txt, width=800, height=500, min_font_size=10, max_font_size=60, scale=&quot;log&quot;) image_write(cloud_img, &quot;data/wordcloud.png&quot;) But, seriously, don’t make word clouds except for fun. "],
["summarizing-link-targets.html", "Recipe 12 Summarizing Link Targets 12.1 Problem 12.2 Solution 12.3 Discussion 12.4 See Also", " Recipe 12 Summarizing Link Targets 12.1 Problem You want to summarize the text of a web page that’s indicated by a short URL in a tweet. 12.2 Solution Extract the text from the web page, and then use a natural language processing (NLP) toolkit to help you extract the most important sentences to create a machine-generated abstract. 12.3 Discussion R has more than a few NLP tools to work with. We’ll work with the LSAfun package for this exercise. As the acronym-laden package name implies, it uses Latent Semantic Analysis (LSA) to determine the most important bits in a set of text. We’ll use tweets by data journalist extraordinaire Matt Stiles. Matt works for the Los Angeles Times and I learn a ton from him on a daily basis. He’s on top of everything. Let’s summarise some news he shared recently from the New York Times, Reuters, Washington Post, Five Thirty-Eight and his employer. We’ll limit our exploration to the first three new links we find. library(rtweet) library(LSAfun) library(jerichojars) # hrbrmstr/jerichojars library(jericho) # hrbrmstr/jericho library(tidyverse) stiles &lt;- get_timeline(&quot;stiles&quot;) filter(stiles, str_detect(urls_expanded_url, &quot;nyti|reut|wapo|lat\\\\.ms|53ei&quot;)) %&gt;% # only get tweets with news links pull(urls_expanded_url) %&gt;% # extract the links flatten_chr() %&gt;% # mush them into a nice character vector head(3) %&gt;% # get the first 3 map_chr(~{ httr::GET(.x) %&gt;% # get the URL (I&#39;m lazily calling &quot;fair use&quot; here vs check robots.txt since I&#39;m suggesting you do this for your benefit vs profit) httr::content(as=&quot;text&quot;) %&gt;% # extract the HTML jericho::html_to_text() %&gt;% # strip away extraneous HTML tags LSAfun::genericSummary(k=3) %&gt;% # summarise! paste0(collapse=&quot;\\n\\n&quot;) # easier to see }) %&gt;% walk(cat) ## We will continue to put the fairness and accuracy of everything we publish above all else — and in the inevitable moments we fall short, we will continue to own up to our mistakes, and we’ll strive to do better ## ## We will continue to put the fairness and accuracy of everything we publish above all else — and in the inevitable moments we fall short, we will continue to own up to our mistakes, and we’ll strive to do better ## ## Our report is stronger than ever, thanks to investments in new forms of journalism like interactive graphics, podcasting and digital video and even greater spending in areas like investigative, international and beat reporting Trump is the 45th president of the United States, but he has spent much of his first year in office defying the conventions and norms established by the previous 44, and transforming the presidency in ways that were once unimaginable ## ## Trump essentially calls it fake, making no effort to pretend to be above it all, except to boast that he is stronger, richer, smarter and more successful than anyone else ## ## “The hope would be that given the American people’s reaction to the way he’s handled the presidency, the people running next time will run in the opposite direction Supreme Court CONFIRMED District courts Circuit courts PENDING Obama 1 3 9 9 11 Trump 1 12 7 6 43 White nominees as percent of total Reagan 94% Trump 91 Bush I 89 Bush II 83 Carter 79 Clinton 75 Obama 64 Male nominees Reagan 92% Carter 84 Bush I 81 Trump 81 Bush II 78 Clinton 71 Obama 58 Supreme Court Circuit courts District courts Obama 1 3 9 9 11 CONFIRMED PENDING CONFIRMED PENDING Trump 1 12 7 6 43 CONFIRMED PENDING CONFIRMED PENDING White nominees as percent of total Male nominees Reagan 94% Reagan 92% 91 Carter 84 Trump Bush I 89 Bush I 81 Bush II 83 Trump 81 Carter 79 Bush II 78 75 Clinton Clinton 71 Obama 64 Obama 58 Supreme Court Circuit courts District courts Obama 1 3 9 9 11 CONFIRMED PENDING CONFIRMED PENDING Trump 1 12 7 6 43 CONFIRMED PENDING CONFIRMED PENDING White nominees as percent of total Male nominees Reagan 94% Reagan 92% 91 Carter 84 Trump Bush I 89 Bush I 81 Bush II 83 Trump 81 Carter 79 Bush II 78 75 Clinton Clinton 71 Obama 64 Obama 58 Trump nominee demographics as of Nov ## ## The improvement in sentiment in the private sector shouldn’t be shocking: If you had been told that you would receive a huge tax cut and be freed from thousands of government regulations, wouldn’t you feel better about your business? As for consumers, their improved mood since the election represents a continuation of a trend that began in 2009 as the floodwaters of the financial crisis were starting to recede ## ## Additional uninsured after repeal: Uninsured, in millions, before repeal of mandate 4 7 12 12 12 12 13 Total uninsured, 2025: 28 30 31 31 44 million ’17 ’18 ’19 ’20 ’21 ’22 ’23 ’24 ’25 Additional uninsured after repeal: Uninsured, in millions, before repeal of mandate: Total uninsured, 2025: 4 7 12 12 12 12 13 44 28 30 31 31 million 2017 ’18 ’19 ’20 ’21 ’22 ’23 ’24 ’25 Sources: Kaiser Family Foundation; Congressional Budget Office More, and Whiter, Judges From Trump While the new administration has struggled to advance its legislative priorities, it has (unfortunately) excelled at another of its responsibilities: appointing judges 12.4 See Also As noted, there are other NLP packages. Check out the CRAN Task View on NLP for more resources. "],
["harvesting-friends-and-followers.html", "Recipe 13 Harvesting Friends and Followers 13.1 Problem 13.2 Solution 13.3 Discussion 13.4 See Also", " Recipe 13 Harvesting Friends and Followers 13.1 Problem You want to harvest all of the friends or followers for a particular user. 13.2 Solution Use rtweet::get_followers() or rtweet::get_friends(). 13.3 Discussion The aforementioned rtweet functions give us all the data we need and handle pagination and rate-limits. Let’s see who Brooke Anderson follows and who follows her. She’s an incredibly talented data scientist, weather expert and educator. We’ll pull her followers and friends and work with her data a bit more in future recipes. library(rtweet) library(tidyverse) (brooke_followers &lt;- rtweet::get_followers(&quot;gbwanderson&quot;)) ## # A tibble: 256 x 1 ## user_id ## &lt;chr&gt; ## 1 913819461727195138 ## 2 25819761 ## 3 2198622000 ## 4 59655036 ## 5 769616000593428480 ## 6 2973406683 ## 7 73603242 ## 8 2790116012 ## 9 392787202 ## 10 920639877397364736 ## # ... with 246 more rows (brooke_friends &lt;- rtweet::get_friends(&quot;gbwanderson&quot;)) ## # A tibble: 103 x 2 ## user user_id ## &lt;chr&gt; &lt;chr&gt; ## 1 gbwanderson 3230388598 ## 2 gbwanderson 776596392559177728 ## 3 gbwanderson 1715370056 ## 4 gbwanderson 131498466 ## 5 gbwanderson 97464922 ## 6 gbwanderson 363210621 ## 7 gbwanderson 17203405 ## 8 gbwanderson 910392773081104384 ## 9 gbwanderson 91333167 ## 10 gbwanderson 1568606814 ## # ... with 93 more rows 13.4 See Also Official Twitter API documentation on friends and followers. "],
["performing-setwise-operations-on-friendship-data.html", "Recipe 14 Performing Setwise Operations on Friendship Data 14.1 Problem 14.2 Solution 14.3 Discussion 14.4 See Also", " Recipe 14 Performing Setwise Operations on Friendship Data 14.1 Problem You want to operate on collections of friends and followers to answer questions such as “Who isn’t following me back?”, “Who are my mutual friends?”, and “What friends/followers do certain users have in common?”. 14.2 Solution Use R setwise operations amd rtweet::lookup_friendships(). 14.3 Discussion R has set operations and they’ll do just fine for helping us cook this recipe. If you need a refresher on set operations, check out this introductory lesson from Khan Academy. library(rtweet) library(tidyverse) brooke_followers &lt;- rtweet::get_followers(&quot;gbwanderson&quot;) brooke_friends &lt;- rtweet::get_friends(&quot;gbwanderson&quot;) Now we can see the count of mutual and disperate relationships: # common length(intersect(brooke_followers$user_id, brooke_friends$user_id)) ## [1] 50 # diff length(setdiff(brooke_followers$user_id, brooke_friends$user_id)) ## [1] 206 The Python counterpart to this cookbook suggests Redis as a “big-ish” data solution for performing set operations at-scale. R has at least 3 packages that provide direct support for Redis, so if you need to perform these operations at-scale, cache the info you retrieve from the Twitter API into Redis and then go crazy! 14.4 See Also Google (yes, seriously) redis packages r to see the impressive/diverse number of packages linking R to Redis Official Twitter API documentation on friends and followers. "],
["resolving-user-profile-information.html", "Recipe 15 Resolving User Profile Information 15.1 Problem 15.2 Solution 15.3 Discussion 15.4 See Also", " Recipe 15 Resolving User Profile Information 15.1 Problem You have a collection of ids and need to resolve basic profile information (such as screen names) for these users. 15.2 Solution Use rtweet::lookup_users(). 15.3 Discussion The rtweet interface to the Twitter API makes this task very straightforward. library(rtweet) library(tidyverse) rstats &lt;- rtweet::search_tweets(&quot;#rstats&quot;, n=30) (recent_rtweeters &lt;- lookup_users(unique(rstats$user_id))) ## # A tibble: 29 x 20 ## user_id name screen_name ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 453028244 Lutra Consulting lutraconsulting ## 2 61190451 pacoramon pacoramon ## 3 347261357 David Rubal, CISSP DaveRubal ## 4 97174061 Claudia Vitolo clavitolo ## 5 54220643 Darren Wilkinson wilkinsondi ## 6 379204076 &quot;Cruz Juli\\u00e1n&quot; Cruz_Julian_ ## 7 111561495 Alfie Abdul-Rahman thisisalfie ## 8 169920416 &quot;h(o x o_)m\\uff1c Moanin&#39;&quot; hoxo_m ## 9 1579555238 Peter Meissner marvin_dpr ## 10 720477266 Luz Ka databayou ## # ... with 19 more rows, and 17 more variables: location &lt;chr&gt;, ## # description &lt;chr&gt;, url &lt;chr&gt;, protected &lt;lgl&gt;, followers_count &lt;int&gt;, ## # friends_count &lt;int&gt;, listed_count &lt;int&gt;, statuses_count &lt;int&gt;, ## # favourites_count &lt;int&gt;, account_created_at &lt;dttm&gt;, verified &lt;lgl&gt;, ## # profile_url &lt;chr&gt;, profile_expanded_url &lt;chr&gt;, account_lang &lt;chr&gt;, ## # profile_banner_url &lt;chr&gt;, profile_background_url &lt;chr&gt;, ## # profile_image_url &lt;chr&gt; glimpse(recent_rtweeters) ## Observations: 29 ## Variables: 20 ## $ user_id &lt;chr&gt; &quot;453028244&quot;, &quot;61190451&quot;, &quot;347261357&quot;, &quot;... ## $ name &lt;chr&gt; &quot;Lutra Consulting&quot;, &quot;pacoramon&quot;, &quot;David... ## $ screen_name &lt;chr&gt; &quot;lutraconsulting&quot;, &quot;pacoramon&quot;, &quot;DaveRu... ## $ location &lt;chr&gt; &quot;United Kingdom&quot;, &quot;Zaragoza&quot;, &quot;Washingt... ## $ description &lt;chr&gt; &quot;Lutra Consulting Ltd provides consulta... ## $ url &lt;chr&gt; &quot;http://t.co/mKCfOH5S4j&quot;, &quot;https://t.co... ## $ protected &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALS... ## $ followers_count &lt;int&gt; 818, 1297, 4003, 567, 636, 325, 265, 26... ## $ friends_count &lt;int&gt; 312, 5001, 3035, 426, 698, 710, 418, 36... ## $ listed_count &lt;int&gt; 34, 493, 2511, 17, 97, 15, 15, 77, 75, ... ## $ statuses_count &lt;int&gt; 1095, 11820, 49591, 492, 1729, 1254, 76... ## $ favourites_count &lt;int&gt; 403, 27902, 18510, 1401, 16, 354, 659, ... ## $ account_created_at &lt;dttm&gt; 2012-01-02 14:10:17, 2009-07-29 13:11:... ## $ verified &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALS... ## $ profile_url &lt;chr&gt; &quot;http://t.co/mKCfOH5S4j&quot;, &quot;https://t.co... ## $ profile_expanded_url &lt;chr&gt; &quot;http://www.lutraconsulting.co.uk&quot;, &quot;ht... ## $ account_lang &lt;chr&gt; &quot;en&quot;, &quot;es&quot;, &quot;en&quot;, &quot;en&quot;, &quot;en&quot;, &quot;es&quot;, &quot;en... ## $ profile_banner_url &lt;chr&gt; NA, &quot;https://pbs.twimg.com/profile_bann... ## $ profile_background_url &lt;chr&gt; &quot;http://abs.twimg.com/images/themes/the... ## $ profile_image_url &lt;chr&gt; &quot;http://pbs.twimg.com/profile_images/52... 15.4 See Also Official Twitter API documentation on users. "],
["crawling-followers-to-approximate-primary-influence.html", "Recipe 16 Crawling Followers to Approximate Primary Influence 16.1 Problem 16.2 Solution 16.3 Discussion 16.4 See Also", " Recipe 16 Crawling Followers to Approximate Primary Influence 16.1 Problem You want to approximate someone’s influence based upon their popularity and the popularity of their followers. 16.2 Solution Use the rtweet::lookup_users() and rtweet::get_followers() combination to pull primary influence and derive “primary influence” based on “followers-of-followers” counts. 16.3 Discussion “Influence” is extremely more nuanced than both what the original Python chaper delved into and what this exercise shows. Building “#-removed” total reach counts from a large tree traversal (as the Python version suggests) is worthless on face-value since it doesn’t take into account how many times any of the ‘n-depth’ of followers ever retweeted or even favorited content posted by the seminal user over the course of a certain period. Without gathering such stats, multi-depth “followers-of-followers” is nigh meaningliess. However, once-removed (so the follower counts of those directly following the target user) has some merit. Marketing folks have varying names for this statistic, so we’ll just call it “primary influece” since there is legitimate potential of reaching this once-removed audience. Ideally, the retweet- and fav-counts should be factored in, but that can be added on as an exercise. Let’s create a helper function that will capture a snapshot of this priamry influence metric. It will take in a user id or name, pull in that user info and the details of their followers and then sum up all the follower counts to get the overall reach number. It returns this information (so it can be processed again without API calls) but also produces a graph of the “number of followers” distribution of the first-level followers. This is usually a heavily skewed distribution so the function also defaults to a log scale, but can be overriden to use a linear scale (log scale will be the correct choice the vast majority of the time, but the fuction can be modified — as an exercise – to test the distribution and auto-pick scales). library(rtweet) library(hrbrthemes) library(tidyverse) influence_snapshot &lt;- function(user, trans=c(&quot;log10&quot;, &quot;identity&quot;)) { user &lt;- user[1] trans &lt;- match.arg(tolower(trimws(trans[1])), c(&quot;log10&quot;, &quot;identity&quot;)) user_info &lt;- lookup_users(user) user_followers &lt;- get_followers(user_info$user_id) uf_details &lt;- lookup_users(user_followers$user_id) primary_influence &lt;- scales::comma(sum(c(uf_details$followers_count, user_info$followers_count))) filter(uf_details, followers_count &gt; 0) %&gt;% ggplot(aes(followers_count)) + geom_density(aes(y=..count..), color=&quot;lightslategray&quot;, fill=&quot;lightslategray&quot;, alpha=2/3, size=1) + scale_x_continuous(expand=c(0,0), trans=&quot;log10&quot;, labels=scales::comma) + scale_y_comma() + labs( x=&quot;Number of Followers of Followers (log scale)&quot;, y=&quot;Number of Followers&quot;, title=sprintf(&quot;Follower chain distribution of %s (@%s)&quot;, user_info$name, user_info$screen_name), subtitle=sprintf(&quot;Follower count: %s; Primary influence/reach: %s&quot;, scales::comma(user_info$followers_count), scales::comma(primary_influence)) ) + theme_ipsum_rc(grid=&quot;XY&quot;) -&gt; gg print(gg) return(invisible(list(user_info=user_info, follower_details=uf_details))) } Let’s run it on Julia Silge, an incredibly talented data scientist over at Stack Overflow and co-author of Tidy Text Mining with R — a book that should be on your shelf especially if you’re doing Twitter mining. juliasilge &lt;- influence_snapshot(&quot;juliasilge&quot;) glimpse(juliasilge) ## List of 2 ## $ user_info :Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 1 obs. of 20 variables: ## ..$ user_id : chr &quot;13074042&quot; ## ..$ name : chr &quot;Julia Silge&quot; ## ..$ screen_name : chr &quot;juliasilge&quot; ## ..$ location : chr &quot;Salt Lake City, UT&quot; ## ..$ description : chr &quot;Data science and visualization at Stack Overflow, #rstats, author of Text Mining with R, parenthood, reading, f&quot;| __truncated__ ## ..$ url : chr &quot;https://t.co/0LpY8Ihz2B&quot; ## ..$ protected : logi FALSE ## ..$ followers_count : int 10910 ## ..$ friends_count : int 445 ## ..$ listed_count : int 410 ## ..$ statuses_count : int 16365 ## ..$ favourites_count : int 19811 ## ..$ account_created_at : POSIXct[1:1], format: &quot;2008-02-05 00:47:07&quot; ## ..$ verified : logi FALSE ## ..$ profile_url : chr &quot;https://t.co/0LpY8Ihz2B&quot; ## ..$ profile_expanded_url : chr &quot;http://juliasilge.com/&quot; ## ..$ account_lang : chr &quot;en&quot; ## ..$ profile_banner_url : chr &quot;https://pbs.twimg.com/profile_banners/13074042/1511394461&quot; ## ..$ profile_background_url: chr &quot;http://abs.twimg.com/images/themes/theme13/bg.gif&quot; ## ..$ profile_image_url : chr &quot;http://pbs.twimg.com/profile_images/930639796510244865/D_N-CofS_normal.jpg&quot; ## ..- attr(*, &quot;tweets&quot;)=Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 1 obs. of 68 variables: ## .. ..$ status_id : chr &quot;949090073693204480&quot; ## .. ..$ created_at : POSIXct[1:1], format: &quot;2018-01-05 01:28:01&quot; ## .. ..$ user_id : chr &quot;13074042&quot; ## .. ..$ screen_name : chr &quot;juliasilge&quot; ## .. ..$ text : chr &quot;RT @statwonk: Analysts, scientists and statisticians know that #bigdata is a joke. Why? Data are uncountable an&quot;| __truncated__ ## .. ..$ source : chr &quot;Twitter for iPhone&quot; ## .. ..$ display_text_width : int NA ## .. ..$ reply_to_status_id : logi NA ## .. ..$ reply_to_user_id : logi NA ## .. ..$ reply_to_screen_name : logi NA ## .. ..$ is_quote : logi FALSE ## .. ..$ is_retweet : logi TRUE ## .. ..$ favorite_count : int 0 ## .. ..$ retweet_count : int 6 ## .. ..$ hashtags :List of 1 ## .. ..$ symbols :List of 1 ## .. ..$ urls_url :List of 1 ## .. ..$ urls_t.co :List of 1 ## .. ..$ urls_expanded_url :List of 1 ## .. ..$ media_url :List of 1 ## .. ..$ media_t.co :List of 1 ## .. ..$ media_expanded_url :List of 1 ## .. ..$ media_type :List of 1 ## .. ..$ ext_media_url :List of 1 ## .. ..$ ext_media_t.co :List of 1 ## .. ..$ ext_media_expanded_url :List of 1 ## .. ..$ ext_media_type : chr NA ## .. ..$ mentions_user_id :List of 1 ## .. ..$ mentions_screen_name :List of 1 ## .. ..$ lang : chr &quot;en&quot; ## .. ..$ quoted_status_id : chr NA ## .. ..$ quoted_text : chr NA ## .. ..$ quoted_created_at : POSIXct[1:1], format: NA ## .. ..$ quoted_source : chr NA ## .. ..$ quoted_favorite_count : int NA ## .. ..$ quoted_retweet_count : int NA ## .. ..$ quoted_user_id : chr NA ## .. ..$ quoted_screen_name : chr NA ## .. ..$ quoted_name : chr NA ## .. ..$ quoted_followers_count : int NA ## .. ..$ quoted_friends_count : int NA ## .. ..$ quoted_statuses_count : int NA ## .. ..$ quoted_location : chr NA ## .. ..$ quoted_description : chr NA ## .. ..$ quoted_verified : logi NA ## .. ..$ retweet_status_id : chr &quot;949042404455219201&quot; ## .. ..$ retweet_text : chr &quot;Analysts, scientists and statisticians know that #bigdata is a joke. Why? Data are uncountable and infinite. On&quot;| __truncated__ ## .. ..$ retweet_created_at : POSIXct[1:1], format: &quot;2018-01-04 22:18:36&quot; ## .. ..$ retweet_source : chr NA ## .. ..$ retweet_favorite_count : int 21 ## .. ..$ retweet_user_id : chr NA ## .. ..$ retweet_screen_name : chr NA ## .. ..$ retweet_name : chr NA ## .. ..$ retweet_followers_count: int NA ## .. ..$ retweet_friends_count : int NA ## .. ..$ retweet_statuses_count : int NA ## .. ..$ retweet_location : chr NA ## .. ..$ retweet_description : chr NA ## .. ..$ retweet_verified : logi NA ## .. ..$ place_url : chr NA ## .. ..$ place_name : chr NA ## .. ..$ place_full_name : chr NA ## .. ..$ place_type : chr NA ## .. ..$ country : chr NA ## .. ..$ country_code : chr NA ## .. ..$ geo_coords :List of 1 ## .. ..$ coords_coords :List of 1 ## .. ..$ bbox_coords :List of 1 ## $ follower_details:Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 5000 obs. of 20 variables: ## ..$ user_id : chr [1:5000] &quot;30197167&quot; &quot;23437966&quot; &quot;944279909521911809&quot; &quot;934426253708464128&quot; ... ## ..$ name : chr [1:5000] &quot;Surajit Dhar&quot; &quot;Helen Graham&quot; &quot;DouglasiMorgan&quot; &quot;kamex kenneth&quot; ... ## ..$ screen_name : chr [1:5000] &quot;nagasuraj&quot; &quot;helngram&quot; &quot;Douglas2Morgan&quot; &quot;KamexKenneth&quot; ... ## ..$ location : chr [1:5000] &quot;&quot; &quot;Edinburgh&quot; &quot;&quot; &quot;La Canada Flintridge, CA&quot; ... ## ..$ description : chr [1:5000] &quot;&quot; &quot;I torture data for fun and profit. Still a cheesecake enthusiast.&quot; &quot;&quot; &quot;Happy&quot; ... ## ..$ url : chr [1:5000] NA NA NA NA ... ## ..$ protected : logi [1:5000] TRUE FALSE FALSE FALSE FALSE FALSE ... ## ..$ followers_count : int [1:5000] 18 99 243 155 2 6172 56 215 427 5 ... ## ..$ friends_count : int [1:5000] 248 382 2806 1521 74 4020 284 884 957 179 ... ## ..$ listed_count : int [1:5000] 0 4 0 0 0 201 4 2 53 0 ... ## ..$ statuses_count : int [1:5000] 92 771 0 1 13 9720 152 1026 2394 6 ... ## ..$ favourites_count : int [1:5000] 30 107 0 8 1 13093 259 612 5479 1 ... ## ..$ account_created_at : POSIXct[1:5000], format: &quot;2009-04-10 10:55:17&quot; ... ## ..$ verified : logi [1:5000] FALSE FALSE FALSE FALSE FALSE TRUE ... ## ..$ profile_url : chr [1:5000] NA NA NA NA ... ## ..$ profile_expanded_url : chr [1:5000] NA NA NA NA ... ## ..$ account_lang : chr [1:5000] &quot;en&quot; &quot;en&quot; &quot;en&quot; &quot;en&quot; ... ## ..$ profile_banner_url : chr [1:5000] NA &quot;https://pbs.twimg.com/profile_banners/23437966/1362861613&quot; &quot;https://pbs.twimg.com/profile_banners/944279909521911809/1513973832&quot; NA ... ## ..$ profile_background_url: chr [1:5000] &quot;http://abs.twimg.com/images/themes/theme1/bg.png&quot; &quot;http://pbs.twimg.com/profile_background_images/5966931/xmas_002.jpg&quot; NA NA ... ## ..$ profile_image_url : chr [1:5000] &quot;http://pbs.twimg.com/profile_images/3619425574/017e3c69373add7399c0689d70d5e3b5_normal.jpeg&quot; &quot;http://pbs.twimg.com/profile_images/378800000858153027/-lbO7veR_normal.jpeg&quot; &quot;http://pbs.twimg.com/profile_images/944301258415984640/NY--VNaG_normal.jpg&quot; &quot;http://pbs.twimg.com/profile_images/934426923584966657/GJUKnQuG_normal.jpg&quot; ... ## ..- attr(*, &quot;tweets&quot;)=Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 5000 obs. of 68 variables: ## .. ..$ status_id : chr [1:5000] NA &quot;949208591524945920&quot; NA &quot;934660498246852608&quot; ... ## .. ..$ created_at : POSIXct[1:5000], format: NA ... ## .. ..$ user_id : chr [1:5000] &quot;30197167&quot; &quot;23437966&quot; &quot;944279909521911809&quot; &quot;934426253708464128&quot; ... ## .. ..$ screen_name : chr [1:5000] &quot;nagasuraj&quot; &quot;helngram&quot; &quot;Douglas2Morgan&quot; &quot;KamexKenneth&quot; ... ## .. ..$ text : chr [1:5000] NA &quot;Every time you drink raw water, somewhere in the great beyond Darwin does a massive facepalm but also feels a bit vindicated.&quot; NA &quot;@ConnLoraine Lovely&quot; ... ## .. ..$ source : chr [1:5000] NA &quot;Twitter for Android&quot; NA &quot;Twitter for iPhone&quot; ... ## .. ..$ display_text_width : int [1:5000] NA NA NA NA NA NA NA NA NA NA ... ## .. ..$ reply_to_status_id : chr [1:5000] NA NA NA &quot;934643010813358081&quot; ... ## .. ..$ reply_to_user_id : chr [1:5000] NA NA NA &quot;893460901470154752&quot; ... ## .. ..$ reply_to_screen_name : chr [1:5000] NA NA NA &quot;ConnLoraine&quot; ... ## .. ..$ is_quote : logi [1:5000] FALSE FALSE FALSE FALSE FALSE FALSE ... ## .. ..$ is_retweet : logi [1:5000] FALSE FALSE FALSE FALSE FALSE FALSE ... ## .. ..$ favorite_count : int [1:5000] NA 0 NA 46 0 4 1 0 0 0 ... ## .. ..$ retweet_count : int [1:5000] NA 0 NA 7 0 0 0 96 64 0 ... ## .. ..$ hashtags :List of 5000 ## .. ..$ symbols :List of 5000 ## .. ..$ urls_url :List of 5000 ## .. ..$ urls_t.co :List of 5000 ## .. ..$ urls_expanded_url :List of 5000 ## .. ..$ media_url :List of 5000 ## .. ..$ media_t.co :List of 5000 ## .. ..$ media_expanded_url :List of 5000 ## .. ..$ media_type :List of 5000 ## .. ..$ ext_media_url :List of 5000 ## .. ..$ ext_media_t.co :List of 5000 ## .. ..$ ext_media_expanded_url :List of 5000 ## .. ..$ ext_media_type : chr [1:5000] NA NA NA NA ... ## .. ..$ mentions_user_id :List of 5000 ## .. ..$ mentions_screen_name :List of 5000 ## .. ..$ lang : chr [1:5000] NA &quot;en&quot; NA &quot;en&quot; ... ## .. ..$ quoted_status_id : chr [1:5000] NA NA NA NA ... ## .. ..$ quoted_text : chr [1:5000] NA NA NA NA ... ## .. ..$ quoted_created_at : POSIXct[1:5000], format: NA ... ## .. ..$ quoted_source : chr [1:5000] NA NA NA NA ... ## .. ..$ quoted_favorite_count : int [1:5000] NA NA NA NA NA NA NA NA NA NA ... ## .. ..$ quoted_retweet_count : int [1:5000] NA NA NA NA NA NA NA NA NA NA ... ## .. ..$ quoted_user_id : chr [1:5000] NA NA NA NA ... ## .. ..$ quoted_screen_name : chr [1:5000] NA NA NA NA ... ## .. ..$ quoted_name : chr [1:5000] NA NA NA NA ... ## .. ..$ quoted_followers_count : int [1:5000] NA NA NA NA NA NA NA NA NA NA ... ## .. ..$ quoted_friends_count : int [1:5000] NA NA NA NA NA NA NA NA NA NA ... ## .. ..$ quoted_statuses_count : int [1:5000] NA NA NA NA NA NA NA NA NA NA ... ## .. ..$ quoted_location : chr [1:5000] NA NA NA NA ... ## .. ..$ quoted_description : chr [1:5000] NA NA NA NA ... ## .. ..$ quoted_verified : logi [1:5000] NA NA NA NA NA NA ... ## .. ..$ retweet_status_id : chr [1:5000] NA NA NA NA ... ## .. ..$ retweet_text : chr [1:5000] NA NA NA NA ... ## .. ..$ retweet_created_at : POSIXct[1:5000], format: NA ... ## .. ..$ retweet_source : chr [1:5000] NA NA NA NA ... ## .. ..$ retweet_favorite_count : int [1:5000] NA NA NA NA NA NA NA 169 162 NA ... ## .. ..$ retweet_user_id : chr [1:5000] NA NA NA NA ... ## .. ..$ retweet_screen_name : chr [1:5000] NA NA NA NA ... ## .. ..$ retweet_name : chr [1:5000] NA NA NA NA ... ## .. ..$ retweet_followers_count: int [1:5000] NA NA NA NA NA NA NA NA NA NA ... ## .. ..$ retweet_friends_count : int [1:5000] NA NA NA NA NA NA NA NA NA NA ... ## .. ..$ retweet_statuses_count : int [1:5000] NA NA NA NA NA NA NA NA NA NA ... ## .. ..$ retweet_location : chr [1:5000] NA NA NA NA ... ## .. ..$ retweet_description : chr [1:5000] NA NA NA NA ... ## .. ..$ retweet_verified : logi [1:5000] NA NA NA NA NA NA ... ## .. ..$ place_url : chr [1:5000] NA NA NA NA ... ## .. ..$ place_name : chr [1:5000] NA NA NA NA ... ## .. ..$ place_full_name : chr [1:5000] NA NA NA NA ... ## .. ..$ place_type : chr [1:5000] NA NA NA NA ... ## .. ..$ country : chr [1:5000] NA NA NA NA ... ## .. ..$ country_code : chr [1:5000] NA NA NA NA ... ## .. ..$ geo_coords :List of 5000 ## .. ..$ coords_coords :List of 5000 ## .. ..$ bbox_coords :List of 5000 You’ll see that distribution shape quite a bit given the general nature of the social structure of Twitter. Don’t believe that? Let’s do one more, this time for Maëlle Salmon, another incredibly talented data scientist with a blog you must follow if you want to learn how to do fun and useful things with R.L ma_salmon &lt;- influence_snapshot(&quot;ma_salmon&quot;) glimpse(juliasilge) ## List of 2 ## $ user_info :Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 1 obs. of 20 variables: ## ..$ user_id : chr &quot;13074042&quot; ## ..$ name : chr &quot;Julia Silge&quot; ## ..$ screen_name : chr &quot;juliasilge&quot; ## ..$ location : chr &quot;Salt Lake City, UT&quot; ## ..$ description : chr &quot;Data science and visualization at Stack Overflow, #rstats, author of Text Mining with R, parenthood, reading, f&quot;| __truncated__ ## ..$ url : chr &quot;https://t.co/0LpY8Ihz2B&quot; ## ..$ protected : logi FALSE ## ..$ followers_count : int 10910 ## ..$ friends_count : int 445 ## ..$ listed_count : int 410 ## ..$ statuses_count : int 16365 ## ..$ favourites_count : int 19811 ## ..$ account_created_at : POSIXct[1:1], format: &quot;2008-02-05 00:47:07&quot; ## ..$ verified : logi FALSE ## ..$ profile_url : chr &quot;https://t.co/0LpY8Ihz2B&quot; ## ..$ profile_expanded_url : chr &quot;http://juliasilge.com/&quot; ## ..$ account_lang : chr &quot;en&quot; ## ..$ profile_banner_url : chr &quot;https://pbs.twimg.com/profile_banners/13074042/1511394461&quot; ## ..$ profile_background_url: chr &quot;http://abs.twimg.com/images/themes/theme13/bg.gif&quot; ## ..$ profile_image_url : chr &quot;http://pbs.twimg.com/profile_images/930639796510244865/D_N-CofS_normal.jpg&quot; ## ..- attr(*, &quot;tweets&quot;)=Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 1 obs. of 68 variables: ## .. ..$ status_id : chr &quot;949090073693204480&quot; ## .. ..$ created_at : POSIXct[1:1], format: &quot;2018-01-05 01:28:01&quot; ## .. ..$ user_id : chr &quot;13074042&quot; ## .. ..$ screen_name : chr &quot;juliasilge&quot; ## .. ..$ text : chr &quot;RT @statwonk: Analysts, scientists and statisticians know that #bigdata is a joke. Why? Data are uncountable an&quot;| __truncated__ ## .. ..$ source : chr &quot;Twitter for iPhone&quot; ## .. ..$ display_text_width : int NA ## .. ..$ reply_to_status_id : logi NA ## .. ..$ reply_to_user_id : logi NA ## .. ..$ reply_to_screen_name : logi NA ## .. ..$ is_quote : logi FALSE ## .. ..$ is_retweet : logi TRUE ## .. ..$ favorite_count : int 0 ## .. ..$ retweet_count : int 6 ## .. ..$ hashtags :List of 1 ## .. ..$ symbols :List of 1 ## .. ..$ urls_url :List of 1 ## .. ..$ urls_t.co :List of 1 ## .. ..$ urls_expanded_url :List of 1 ## .. ..$ media_url :List of 1 ## .. ..$ media_t.co :List of 1 ## .. ..$ media_expanded_url :List of 1 ## .. ..$ media_type :List of 1 ## .. ..$ ext_media_url :List of 1 ## .. ..$ ext_media_t.co :List of 1 ## .. ..$ ext_media_expanded_url :List of 1 ## .. ..$ ext_media_type : chr NA ## .. ..$ mentions_user_id :List of 1 ## .. ..$ mentions_screen_name :List of 1 ## .. ..$ lang : chr &quot;en&quot; ## .. ..$ quoted_status_id : chr NA ## .. ..$ quoted_text : chr NA ## .. ..$ quoted_created_at : POSIXct[1:1], format: NA ## .. ..$ quoted_source : chr NA ## .. ..$ quoted_favorite_count : int NA ## .. ..$ quoted_retweet_count : int NA ## .. ..$ quoted_user_id : chr NA ## .. ..$ quoted_screen_name : chr NA ## .. ..$ quoted_name : chr NA ## .. ..$ quoted_followers_count : int NA ## .. ..$ quoted_friends_count : int NA ## .. ..$ quoted_statuses_count : int NA ## .. ..$ quoted_location : chr NA ## .. ..$ quoted_description : chr NA ## .. ..$ quoted_verified : logi NA ## .. ..$ retweet_status_id : chr &quot;949042404455219201&quot; ## .. ..$ retweet_text : chr &quot;Analysts, scientists and statisticians know that #bigdata is a joke. Why? Data are uncountable and infinite. On&quot;| __truncated__ ## .. ..$ retweet_created_at : POSIXct[1:1], format: &quot;2018-01-04 22:18:36&quot; ## .. ..$ retweet_source : chr NA ## .. ..$ retweet_favorite_count : int 21 ## .. ..$ retweet_user_id : chr NA ## .. ..$ retweet_screen_name : chr NA ## .. ..$ retweet_name : chr NA ## .. ..$ retweet_followers_count: int NA ## .. ..$ retweet_friends_count : int NA ## .. ..$ retweet_statuses_count : int NA ## .. ..$ retweet_location : chr NA ## .. ..$ retweet_description : chr NA ## .. ..$ retweet_verified : logi NA ## .. ..$ place_url : chr NA ## .. ..$ place_name : chr NA ## .. ..$ place_full_name : chr NA ## .. ..$ place_type : chr NA ## .. ..$ country : chr NA ## .. ..$ country_code : chr NA ## .. ..$ geo_coords :List of 1 ## .. ..$ coords_coords :List of 1 ## .. ..$ bbox_coords :List of 1 ## $ follower_details:Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 5000 obs. of 20 variables: ## ..$ user_id : chr [1:5000] &quot;30197167&quot; &quot;23437966&quot; &quot;944279909521911809&quot; &quot;934426253708464128&quot; ... ## ..$ name : chr [1:5000] &quot;Surajit Dhar&quot; &quot;Helen Graham&quot; &quot;DouglasiMorgan&quot; &quot;kamex kenneth&quot; ... ## ..$ screen_name : chr [1:5000] &quot;nagasuraj&quot; &quot;helngram&quot; &quot;Douglas2Morgan&quot; &quot;KamexKenneth&quot; ... ## ..$ location : chr [1:5000] &quot;&quot; &quot;Edinburgh&quot; &quot;&quot; &quot;La Canada Flintridge, CA&quot; ... ## ..$ description : chr [1:5000] &quot;&quot; &quot;I torture data for fun and profit. Still a cheesecake enthusiast.&quot; &quot;&quot; &quot;Happy&quot; ... ## ..$ url : chr [1:5000] NA NA NA NA ... ## ..$ protected : logi [1:5000] TRUE FALSE FALSE FALSE FALSE FALSE ... ## ..$ followers_count : int [1:5000] 18 99 243 155 2 6172 56 215 427 5 ... ## ..$ friends_count : int [1:5000] 248 382 2806 1521 74 4020 284 884 957 179 ... ## ..$ listed_count : int [1:5000] 0 4 0 0 0 201 4 2 53 0 ... ## ..$ statuses_count : int [1:5000] 92 771 0 1 13 9720 152 1026 2394 6 ... ## ..$ favourites_count : int [1:5000] 30 107 0 8 1 13093 259 612 5479 1 ... ## ..$ account_created_at : POSIXct[1:5000], format: &quot;2009-04-10 10:55:17&quot; ... ## ..$ verified : logi [1:5000] FALSE FALSE FALSE FALSE FALSE TRUE ... ## ..$ profile_url : chr [1:5000] NA NA NA NA ... ## ..$ profile_expanded_url : chr [1:5000] NA NA NA NA ... ## ..$ account_lang : chr [1:5000] &quot;en&quot; &quot;en&quot; &quot;en&quot; &quot;en&quot; ... ## ..$ profile_banner_url : chr [1:5000] NA &quot;https://pbs.twimg.com/profile_banners/23437966/1362861613&quot; &quot;https://pbs.twimg.com/profile_banners/944279909521911809/1513973832&quot; NA ... ## ..$ profile_background_url: chr [1:5000] &quot;http://abs.twimg.com/images/themes/theme1/bg.png&quot; &quot;http://pbs.twimg.com/profile_background_images/5966931/xmas_002.jpg&quot; NA NA ... ## ..$ profile_image_url : chr [1:5000] &quot;http://pbs.twimg.com/profile_images/3619425574/017e3c69373add7399c0689d70d5e3b5_normal.jpeg&quot; &quot;http://pbs.twimg.com/profile_images/378800000858153027/-lbO7veR_normal.jpeg&quot; &quot;http://pbs.twimg.com/profile_images/944301258415984640/NY--VNaG_normal.jpg&quot; &quot;http://pbs.twimg.com/profile_images/934426923584966657/GJUKnQuG_normal.jpg&quot; ... ## ..- attr(*, &quot;tweets&quot;)=Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 5000 obs. of 68 variables: ## .. ..$ status_id : chr [1:5000] NA &quot;949208591524945920&quot; NA &quot;934660498246852608&quot; ... ## .. ..$ created_at : POSIXct[1:5000], format: NA ... ## .. ..$ user_id : chr [1:5000] &quot;30197167&quot; &quot;23437966&quot; &quot;944279909521911809&quot; &quot;934426253708464128&quot; ... ## .. ..$ screen_name : chr [1:5000] &quot;nagasuraj&quot; &quot;helngram&quot; &quot;Douglas2Morgan&quot; &quot;KamexKenneth&quot; ... ## .. ..$ text : chr [1:5000] NA &quot;Every time you drink raw water, somewhere in the great beyond Darwin does a massive facepalm but also feels a bit vindicated.&quot; NA &quot;@ConnLoraine Lovely&quot; ... ## .. ..$ source : chr [1:5000] NA &quot;Twitter for Android&quot; NA &quot;Twitter for iPhone&quot; ... ## .. ..$ display_text_width : int [1:5000] NA NA NA NA NA NA NA NA NA NA ... ## .. ..$ reply_to_status_id : chr [1:5000] NA NA NA &quot;934643010813358081&quot; ... ## .. ..$ reply_to_user_id : chr [1:5000] NA NA NA &quot;893460901470154752&quot; ... ## .. ..$ reply_to_screen_name : chr [1:5000] NA NA NA &quot;ConnLoraine&quot; ... ## .. ..$ is_quote : logi [1:5000] FALSE FALSE FALSE FALSE FALSE FALSE ... ## .. ..$ is_retweet : logi [1:5000] FALSE FALSE FALSE FALSE FALSE FALSE ... ## .. ..$ favorite_count : int [1:5000] NA 0 NA 46 0 4 1 0 0 0 ... ## .. ..$ retweet_count : int [1:5000] NA 0 NA 7 0 0 0 96 64 0 ... ## .. ..$ hashtags :List of 5000 ## .. ..$ symbols :List of 5000 ## .. ..$ urls_url :List of 5000 ## .. ..$ urls_t.co :List of 5000 ## .. ..$ urls_expanded_url :List of 5000 ## .. ..$ media_url :List of 5000 ## .. ..$ media_t.co :List of 5000 ## .. ..$ media_expanded_url :List of 5000 ## .. ..$ media_type :List of 5000 ## .. ..$ ext_media_url :List of 5000 ## .. ..$ ext_media_t.co :List of 5000 ## .. ..$ ext_media_expanded_url :List of 5000 ## .. ..$ ext_media_type : chr [1:5000] NA NA NA NA ... ## .. ..$ mentions_user_id :List of 5000 ## .. ..$ mentions_screen_name :List of 5000 ## .. ..$ lang : chr [1:5000] NA &quot;en&quot; NA &quot;en&quot; ... ## .. ..$ quoted_status_id : chr [1:5000] NA NA NA NA ... ## .. ..$ quoted_text : chr [1:5000] NA NA NA NA ... ## .. ..$ quoted_created_at : POSIXct[1:5000], format: NA ... ## .. ..$ quoted_source : chr [1:5000] NA NA NA NA ... ## .. ..$ quoted_favorite_count : int [1:5000] NA NA NA NA NA NA NA NA NA NA ... ## .. ..$ quoted_retweet_count : int [1:5000] NA NA NA NA NA NA NA NA NA NA ... ## .. ..$ quoted_user_id : chr [1:5000] NA NA NA NA ... ## .. ..$ quoted_screen_name : chr [1:5000] NA NA NA NA ... ## .. ..$ quoted_name : chr [1:5000] NA NA NA NA ... ## .. ..$ quoted_followers_count : int [1:5000] NA NA NA NA NA NA NA NA NA NA ... ## .. ..$ quoted_friends_count : int [1:5000] NA NA NA NA NA NA NA NA NA NA ... ## .. ..$ quoted_statuses_count : int [1:5000] NA NA NA NA NA NA NA NA NA NA ... ## .. ..$ quoted_location : chr [1:5000] NA NA NA NA ... ## .. ..$ quoted_description : chr [1:5000] NA NA NA NA ... ## .. ..$ quoted_verified : logi [1:5000] NA NA NA NA NA NA ... ## .. ..$ retweet_status_id : chr [1:5000] NA NA NA NA ... ## .. ..$ retweet_text : chr [1:5000] NA NA NA NA ... ## .. ..$ retweet_created_at : POSIXct[1:5000], format: NA ... ## .. ..$ retweet_source : chr [1:5000] NA NA NA NA ... ## .. ..$ retweet_favorite_count : int [1:5000] NA NA NA NA NA NA NA 169 162 NA ... ## .. ..$ retweet_user_id : chr [1:5000] NA NA NA NA ... ## .. ..$ retweet_screen_name : chr [1:5000] NA NA NA NA ... ## .. ..$ retweet_name : chr [1:5000] NA NA NA NA ... ## .. ..$ retweet_followers_count: int [1:5000] NA NA NA NA NA NA NA NA NA NA ... ## .. ..$ retweet_friends_count : int [1:5000] NA NA NA NA NA NA NA NA NA NA ... ## .. ..$ retweet_statuses_count : int [1:5000] NA NA NA NA NA NA NA NA NA NA ... ## .. ..$ retweet_location : chr [1:5000] NA NA NA NA ... ## .. ..$ retweet_description : chr [1:5000] NA NA NA NA ... ## .. ..$ retweet_verified : logi [1:5000] NA NA NA NA NA NA ... ## .. ..$ place_url : chr [1:5000] NA NA NA NA ... ## .. ..$ place_name : chr [1:5000] NA NA NA NA ... ## .. ..$ place_full_name : chr [1:5000] NA NA NA NA ... ## .. ..$ place_type : chr [1:5000] NA NA NA NA ... ## .. ..$ country : chr [1:5000] NA NA NA NA ... ## .. ..$ country_code : chr [1:5000] NA NA NA NA ... ## .. ..$ geo_coords :List of 5000 ## .. ..$ coords_coords :List of 5000 ## .. ..$ bbox_coords :List of 5000 16.4 See Also Simply Measured’s guide to measuring influence on Twitter "],
["analyzing-friendship-relationships-such-as-friends-of-friends.html", "Recipe 17 Analyzing Friendship Relationships such as Friends of Friends 17.1 Problem 17.2 Solution 17.3 Discussion 17.4 See Also", " Recipe 17 Analyzing Friendship Relationships such as Friends of Friends 17.1 Problem You want to create a graph that facilitates the analysis of interesting relationships amongst users, such as friends of friends. 17.2 Solution Systematically harvest all of the friendships for users of interest, and load the data into igraph which offers native graph operations. 17.3 Discussion TBD 17.4 See Also "],
["analyzing-friendship-cliques.html", "Recipe 18 Analyzing Friendship Cliques 18.1 Problem 18.2 Solution 18.3 Discussion 18.4 See Also", " Recipe 18 Analyzing Friendship Cliques 18.1 Problem You want to find the friendship cliques in a graph. 18.2 Solution Construct a graph using igraph and use its built-in functionality to for clique/community detection. 18.3 Discussion TBD 18.4 See Also "],
["analyzing-the-authors-of-tweets-that-appear-in-search-results.html", "Recipe 19 Analyzing the Authors of Tweets that Appear in Search Results 19.1 Problem 19.2 Solution", " Recipe 19 Analyzing the Authors of Tweets that Appear in Search Results 19.1 Problem You want to analyze user profile information as it relates to the authors of tweets that appear in search results. 19.2 Solution Covered in Recipe 15! "],
["visualizing-geodata-with-a-dorling-cartogram.html", "Recipe 20 Visualizing Geodata with a Dorling Cartogram 20.1 Problem 20.2 Solution 20.3 Discussion", " Recipe 20 Visualizing Geodata with a Dorling Cartogram 20.1 Problem You want to visualize geolocation information (for example, the location field from user profile information, included in a batch of tweets such as a search query), in order to determine if there is a correlation between location and some other criterion. 20.2 Solution Devise a heuristic to extract the state from the location information in user profiles and visualize it with a Dorling Cartogram. 20.3 Discussion (As this cookbook’s Python counterpart notes): “A Dorling Cartogram is essentially a bubble chart where each bubble corresponds to a geographic area such as a state, and each bubble is situated as close as possible to its actual location on a map without overlapping with any other bubbles. Since the size and/or color of each bubble can be used to represent meaningful things, a Dorling Cartogram can give you a very intuitive view of data as it relates to geographic boundaries or regions of a larger land mass. The Protovis toolkit comes with some machinery for creating Dorling Cartograms for locations in the United States, and one interesting example of something that you could do builds upon Recipe 19, which demonstrated an approach that you could use to analyze the users who authored tweets from a targeted query.” One seminal, modern example for Dorling catograms is Mike Bostock’s Protovis (a pre-cursor to D3) version I have a love/hate relationship with cartograms. On the one hand, they capture attention by preying on the weakness most of us have to maps. On the other hand, most adults in my home country barely know where their state is on a map when they can see its shape, so most cartograms require extensive labeling and the shape distortions can initially disorient the viewer. Many cartograms also degrade the ability to readily discern the proportions or precision of the underlying data. But, we’re working with Twitter data and the goal for this recipe is to pull a sample of tweets and see where the (geographic) action is at, so using this paticular cartogram style for it is not a terrible choice. NOTE: This recipe and the next (and, final!) recipe both cover Twitter and geographic data. Any reasonable person should disable the association of location information to Tweets for a whole host of reasons which include security and safety. They should also make the location information in their profile human discernable but difficult for machines to process (better still — use fake location data in your profile). However, there are still a cadre of Twitter users who gleefully provide this information — or, disinformation — so we all can process it. Rather than rely on the geolocation data of a tweet, let’s pull down some more #rstats tweets and try to limit the locations of the tweets to just the U.S. (despite disabling assocation of location data, Twitter can still internally, generally figure out where you’re tweeting from, especially if you’re on a mobile device). After that, we’ll lookup the users of the tweets and extract the location information from their user profile. Once we have that location information, we’ll filter it a bit to discern which state it came from. We’ll cover the visualization component after we deal with the data: library(rtweet) library(broom) library(eechidna) library(cartogram) # chxy/cartogram library(hrbrthemes) library(tidyverse) # search twitter for tweets rstats_us &lt;- search_tweets(&quot;#rstats&quot;, 3000, geocode = &quot;2.877742,-97.380979,3000mi&quot;) # geocode request isn&#39;t perfect but helps narrow down # lookup each user (uniquely) so we can grab location information user_info &lt;- lookup_users(unique(rstats_us$user_id)) discard(user_info$location, `==`, &quot;&quot;) %&gt;% # ignore blank data str_match(sprintf(&quot;(%s)&quot;, paste0(state.abb, collapse=&quot;|&quot;))) %&gt;% # try to match U.S. state abbreviations .[,2] %&gt;% # the previous step creates a matrix with column 2 being the extracted information (if any) discard(is.na) %&gt;% # if no state match was found the value is NA so discard this one table() %&gt;% # some habits are hard to break broom::tidy() %&gt;% # but we can tidy them! set_names(c(&quot;state&quot;, &quot;n&quot;)) %&gt;% # these are more representative names tbl_df() %&gt;% # not really necessary but I was printing this when testing arrange(desc(n)) %&gt;% # same as ^^ left_join( as_data_frame(maps::state.carto.center) %&gt;% # join state cartographic center data mutate(state=state.abb) ) %&gt;% # the GitHub-only cartogram package nas a data structure which holds state adjacency information # by specifying that here, it will help make the force-directed cartogram circle positioning more precise (and pretty) filter(state %in% names(cartogram::statenbrs)) -&gt; for_dor glimpse(for_dor) ## Observations: 36 ## Variables: 4 ## $ state &lt;chr&gt; &quot;NY&quot;, &quot;MA&quot;, &quot;PA&quot;, &quot;CA&quot;, &quot;IL&quot;, &quot;NC&quot;, &quot;FL&quot;, &quot;MD&quot;, &quot;TX&quot;, &quot;W... ## $ n &lt;int&gt; 34, 28, 17, 14, 11, 11, 9, 9, 9, 8, 6, 6, 5, 5, 5, 5, 4,... ## $ x &lt;dbl&gt; 8.041600, 9.025060, 7.222050, 1.410693, 4.823002, 6.9985... ## $ y &lt;dbl&gt; 8.746802, 8.684993, 8.029811, 7.337543, 7.757849, 6.5711... The visualization component needs some explanation since it’s a bit hack-ish. Xiaoyue Cheng has had n R cartogram package on GitHub for just over five years. It’s not feature complete but has a (mostly) working Dorling cartogram generator. Carson Sievert incorporated and enhanced some of the cartogram functions for the rOpenSci eechidna package, but uses it internally. Finally, cartogram package has some data sets that make Dorling U.S. state cartogramsa bit more visually appealing. What that all means is we’ll be calling an unexported function from eechidna and using some data from cartogram. This is far from an optimal situation, especially since it also means we won’t be using ggplot2 for the final visualization. But, it works! The code block below starts by setting up some base R plotting parameters, one of which — col=&quot;white&quot; — is going to cause you some grief if you don’t remember to change it to black since it impacts the default color for base R plots. This is also an opportunity to set the font family for the text labels since there is no way to pass text label aesthetics in the dorling() function. We pass in the: state label state center a scaled value for the tweet count state neighbor information and tweak some aesthetics to produce the final plot. This example opted to “connect the dots” to more explicitly show neighbor information. par(family=font_rc, col=&quot;white&quot;) eechidna:::dorling( for_dor$state, for_dor$x, for_dor$y, sqrt(for_dor$n), nbr=cartogram::statenbrs, animation = FALSE, nbredge = TRUE, iteration=100, name.text=TRUE, dist.ratio=1.2, main=&quot;Dorling Cartogram of U.S. #rstats&quot;, xlab=&#39;&#39;, ylab=&#39;&#39;, col=&quot;lightslategray&quot;, frame=FALSE, asp=1, family=font_rc, cex.main=1.75, adj=0 ) -&gt; dor "],
["geocoding-locations-from-profiles-or-elsewhere.html", "Recipe 21 Geocoding Locations from Profiles (or Elsewhere) 21.1 Problem 21.2 Solution 21.3 Discussion 21.4 See Also", " Recipe 21 Geocoding Locations from Profiles (or Elsewhere) 21.1 Problem You want to geocode information in tweets for situations beyond what the Twitter API provides and not just focus on U.S. states as Ecipe 20 did. 21.2 Solution Use a geocoding service/package to translate location strings into more precise geographic information. 21.3 Discussion Recipe 20 focused on extracting U.S. state information from user profiles. But, Twitter is a global service with millions of active users in many countries. Let’s use the Google geocoding API function from the ggmaps package to try to translate user profile location strings into location data. NOTE: Google’s API has a limit of 2,500 calls per day for free, so you’ll need to pay-up or work in daily batches if you have a large amount of Tweet location data to lookup. library(rtweet) library(ggmap) library(tidyverse) rstats_us &lt;- search_tweets(&quot;#rstats&quot;, 3000) user_info &lt;- lookup_users(unique(rstats_us$user_id)) discard(user_info$location, `==`, &quot;&quot;) %&gt;% ggmap::geocode() -&gt; coded coded$location &lt;- discard(user_info$location, `==`, &quot;&quot;) user_info &lt;- left_join(user_info, coded, &quot;location&quot;) ## # A tibble: 503 x 3 ## location lat ## &lt;chr&gt; &lt;dbl&gt; ## 1 Peru -9.189967 ## 2 Richmond, B.C., Canada 49.166590 ## 3 Massachusetts 42.407211 ## 4 Frederick, MD 39.414269 ## 5 Japan 36.204824 ## 6 FMU 34.190425 ## 7 Chicago, IL 41.878114 ## 8 &quot;\\u65e5\\u672c&quot; 36.204824 ## 9 &quot;\\u5317\\u5927\\u30fb\\u74b0\\u5883\\u79d1\\u5b66&quot; 43.072764 ## 10 Stuttgart, Germany 48.775846 ## 11 New York, NY 40.712775 ## 12 Asbury Park, NJ 40.220391 ## 13 Ann Arbor, MI 42.280826 ## 14 Ithaca, NY 42.443961 ## 15 &quot;\\u00dcT: 36.1573208,-95.9526115&quot; 40.532392 ## 16 Houston, TX 29.760427 ## 17 Rome, NY 43.212847 ## 18 Perth, Australia -31.950527 ## 19 Santiago, CL -33.448890 ## 20 Johnston, IA 41.670983 ## 21 Fort Collins, CO 40.585260 ## 22 Hyderabad, India 17.385044 ## 23 Nashville, TN 36.162664 ## 24 Canton, CHN 23.129110 ## 25 &quot;Bogot\\u00e1&quot; 4.710989 ## 26 3052, Australia -37.786236 ## 27 Charlottesville, VA 38.029306 ## 28 Hobart, Tasmania -42.882138 ## 29 moon 40.516977 ## 30 Toronto, Ontario 43.653226 ## # ... with 473 more rows, and 1 more variables: lon &lt;dbl&gt; 21.4 See Also Google’s API is far from perfect, but they have also been collecting gnarly input data for map locations for over a decade, which makes them a good first-choice. You can find more R geocoding packages in the CRAN Web Technologies Task View. "]
]
